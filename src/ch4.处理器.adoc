== 处理器

=== 单周期处理器实现

实现一个单周期处理器需要多个关键模块协同工作，以便在一个时钟周期内完成指令的取指、译码、执行、存储访问和写回操作。这些模块包括控制单元、寄存器文件、算术逻辑单元（ALU）、程序计数器（PC）、指令存储器、数据存储器以及各种多路选择器（MUX）和信号通路（Bus）。

- 程序计数器（PC）

	程序计数器存储当前指令的地址，并在每个时钟周期自动更新以指向下一条指令。PC的输出作为指令存储器的输入地址。对于跳转或分支指令，PC的值可能由控制单元计算并更新。

- 指令存储器

	指令存储器根据 PC 提供的地址，输出当前指令的二进制码。指令由操作码（opcode）、寄存器地址（源寄存器、目标寄存器）和立即数等字段组成，这些字段作为后续模块的输入。

- 控制单元

	控制单元负责解析指令的操作码，生成控制信号以指导其他模块的行为。例如：
	决定 ALU 执行的操作（加、减、逻辑运算等）。
	控制数据存储器的读写行为。
	控制寄存器文件的数据读写方向。
	选择跳转或分支地址。
	控制单元的输出信号连接到 ALU、数据存储器、多路选择器和其他模块。

- 寄存器模块

	寄存器模块存储处理器的操作数。它包含多个通用寄存器：
	根据指令的源寄存器字段，从寄存器文件中读取操作数。
	根据目标寄存器字段，将计算结果写回寄存器文件。
	寄存器文件的读写操作由控制单元生成的控制信号控制。

- 算术逻辑单元（ALU）

	ALU 执行算术和逻辑运算，例如加法、减法、位与、位或等。它的输入操作数来自寄存器模块或立即数，具体取决于指令类型（R 型、I 型等）。ALU 的输出即为运算结果，通常存储回寄存器文件或用于分支条件的判断。

- 数据存储器

	数据存储器用于加载或存储数据，支持内存读写操作：
	加载指令（如 lw）从数据存储器读取数据，并将其送入寄存器文件。
	存储指令（如 sw）将寄存器文件中的数据写入数据存储器。
	数据存储器的地址和数据由指令字段和 ALU 的运算结果决定，其读写行为由控制信号控制。

- 多路选择器（MUX）

	多路选择器用于在多种可能的输入中选择一个作为输出。主要用途包括：
	在立即数和寄存器操作数之间选择 ALU 输入。
	在 ALU 输出和数据存储器输出之间选择寄存器写入的数据。
	在顺序地址和跳转目标地址之间选择 PC 的下一个值。

- 信号通路和总线

	信号通路用于连接各个模块，允许数据和控制信号在模块之间流动。总线是一种共享的通信通道，可用于传递指令、数据或地址。

TIP: p176

通过这些模块的紧密配合，单周期处理器能够在一个时钟周期内完成一条指令的全部执行过程。虽然结构简单，但由于所有操作都必须在单个周期内完成，其性能受限于最慢路径的延迟。

==== 逻辑设计的基本方法

RISC-V实现中的数据通路包含两种不同类型的逻辑单元：处理数据值的单元和存储状态的单元。处理数据值的单元是组合逻辑，它们的输出仅依赖于当前输人。给定相同的输人，组合逻辑单元总是产生相同的输出。例如，ALU就是一个组合逻辑单元。由于组合逻辑单元没有内部存储功能，当给定一组输人时，它总是产生相同的输出。

设计中的其他单元不是组合逻辑，而是包含状态的。如果一个单元有内部存储功能，它就包含状态，称其为状态单元。这是因为关机后重启计算机，通过恢复状态单元的原值，计算机可继续运行，就像没有发生过断电一样。进一步地，这些状态单元可以完整地表征计算机。例如，指令存储器、数据存储器以及寄存器都是状态单元。

一个状态单元至少有两个输人和一个输出。必需的输入是要写入状态单元的数据值和决定何时写入数据值的时钟信号。状态单元的输出提供了在前一个时钟周期写入单元的数据值。例如，逻辑上最简单的一种状态单元是D触发器，它有两个输入(一个数据值和一个时钟）和一个输出。除了触发器，RISC-V的实现中还用到了另外两种状态单元：存储器和寄存器。状态单元何时被写入由时钟确定，但是它随时可以被读。

包含状态的逻辑部件也被称为时序的，因为其输出取决于输人和内部状态。例如，表示寄存器的功能单元的输出取决于所提供的寄存器号和之前写人寄存器的内容。

**时钟同步方法**

时钟同步方法（clocking methodology）规定了信号可以读出和写入的时间。规定信号的读写时间非常重要，因为如果在读信号的同时写信号，那么读到的值可能是该信号的旧值，也可能是新写入的值，甚至可能是二者的混合。计算机设计无法容忍这种不可预测性。时钟同步方法就是为避免这种情况而提出的。

为简单起见，假定我们采用边沿触发的时钟(edge-triggered clocking)，即存储在时序逻辑单元中的所有值仅在时钟边沿更新，这是从低电平快速跳变到高电平（反之亦然）的过程。因为只有状态单元能存储数据值，所有组合逻辑单元都必须从状态单元集合接收输入，并将输出写入状态单元集合。其输入是之前某时钟周期写入的值，输出的值可以在后续时钟周期使用。

==== 数据通路

数据通路是计算机处理器中一个核心的硬件部分，专门用于传输、存储和处理指令和数据。它由寄存器、算术逻辑单元（ALU）、多路选择器（MUX）、数据总线、存储器等模块组成，负责在指令执行过程中完成数据的流动和运算操作。数据通路通过硬件资源的协同工作，将指令的每个步骤具体化，从而实现处理器功能。

数据通路的作用是完成指令执行的全部过程，包括指令的取指、译码、执行、存储访问和写回操作。通过程序计数器（PC），数据通路能够确定当前指令的位置并从指令存储器中读取；通过寄存器文件和 ALU，数据通路可以完成算术和逻辑运算；通过多路选择器和数据总线，数据通路能在不同的硬件模块之间高效地传递数据；通过数据存储器，数据通路支持加载和存储操作。它的设计决定了处理器的性能、效率和指令支持能力，是实现计算任务的硬件基础。

==== 单周期处理器的实现

TIP: 待定

==== 为什么现在不使用单周期实现

尽管单周期设计可以正确工作，但是在现代设计中不采取这种方式，因为它的效率太低。究其原因，是在单周期设计中时钟周期对于每条指令必须等长。这样，处理器中的最长路径决定了时钟周期。这条路径很可能是一条load指令，它连续地使用5个功能单元：指令存储器、寄存器堆、ALU、数据存储器和寄存器堆。虽然CP1为1（见第1章），但由于时钟周期太长，单周期实现的整体性能可能很差。使用单周期设计的代价是显著的，但对于这个小指令集而言，或许是可以接受的。历史上，早期具有简单指令集的计算机确实采用这种实现方式。但是，如果要实现浮点单元或更复杂的指令集，单周期设计根本无法正常工作。由于时钟周期必须满足所有指令中最坏的情况，所以不能使用那些缩短常用指令执行时间而不改变最坏情况的实现技术。因此，单周期实现违反了第1章中加速经常性事件这一设计原则。在4.6节，我们将看到一种称为流水线的实现技术，它使用与单周期相似的数据通路，但吞吐量更高，效率更高。流水线技术通过同时执行多条指令来提高效率。

=== 多周期实现

在多周期实现中，执行中的每一步都需要1个时钟周期。多周期实现允许每个指令多次使用同一个功能单元，只要它在不同的时钟周期内使用。这种共享有助于减少所需的硬件数量。允许指令采用不同数量的时钟周期，以及在单条指令的执行中共享功能单元是多周期设计的主要优势。虽然多周期实现可以降低硬件成本，但今天几乎所有的芯片都使用流水线来提高性能。

多周期处理器是一种通过将指令执行过程划分为多个阶段、在多个时钟周期内完成的处理器设计。相比单周期处理器，多周期处理器可以在不需要重复硬件资源的情况下完成指令执行，从而实现更高的硬件利用率和更灵活的设计。其主要组成模块包括控制单元、程序计数器（PC）、指令存储器、寄存器文件、算术逻辑单元（ALU）、数据存储器和多路选择器等。

多周期处理器的工作流程通过阶段化的方式逐步完成每条指令的执行。首先，程序计数器提供当前指令的地址，指令存储器根据地址取出指令并送入控制单元。控制单元解析指令，生成对应的控制信号，引导寄存器文件从指定寄存器中读取操作数，同时为后续阶段设定路径。接下来，ALU 执行算术或逻辑运算，或者用于计算存储器的访问地址。对于加载或存储指令，ALU 的输出作为地址输入到数据存储器，数据存储器根据指令类型进行读写操作。最后，处理器将运算结果或者从存储器读取的数据写回寄存器文件，完成指令的执行。

在多周期处理器中，每个时钟周期只执行一部分工作，例如取指、译码、执行、存储访问或写回。这种设计允许同一硬件资源（如 ALU 或数据存储器）在不同阶段为不同指令使用，因此相较于单周期处理器，硬件资源需求更低。此外，多周期处理器的控制单元采用有限状态机（FSM）设计，根据当前指令的类型和执行阶段生成精确的控制信号，确保每个模块在正确的时间参与操作。

多周期处理器通过分阶段执行，平衡了性能与硬件资源之间的关系，使其适合于资源有限的系统设计，同时可以支持复杂指令集。然而，由于指令完成时间不固定，其性能通常低于流水线处理器，但更容易实现且硬件开销较低。

=== 流水线概述

流水线是一种能使多条指令重叠执行的实现技术。使用流水线来使指令能重叠执行，以提高性能。即指令级并行（ILP）。目前，流水线技术广泛应用。

下面使用一个比喻概述流水线的概念及相关问题。

任何做洗衣工作的人都不自觉地使用流水线技术。非流水线的洗衣过程包含如下步骤：

1. 将一批脏衣服放入洗衣机。

2. 洗衣机洗完后，将湿衣服取出并放入烘干机

3. 烘干机完成后，将干衣服取出，放在桌上并叠起来

4. 叠好后，请你的室友帮忙把衣服收好。

当这一批衣服收好后，再开始洗下一批脏衣服。

流水线方法花费的时间少得多。当第一批衣服从洗衣机中取出并放人烘干机后，就可以把第二批脏衣服放入洗衣机。当第一批衣服烘干完成后，就可以把它们放在桌上叠起来，同时把洗衣机中洗好的衣服放入烘干机，再将下一批脏衣服放入洗衣机。接着让你的室友把第一批衣服从桌上收好，你开始叠第二批衣服，烘干机开始烘干第三批衣服，同时可以把第四批衣服放人洗衣机。此时，所有的洗衣步骤（称为流水线阶段）在同时工作。只要每个阶段使用不同的资源，我们就可以用流水线的方法完成任务。

流水线的矛盾在于，对于一双脏袜子，从把它放人洗衣机到被烘干、叠好和收起的时间在流水线中并没有缩短；然而对于许多负载来说，流水线更快的原因是所有工作都在并行地执行。所以单位时间能够完成更多工作，流水线提高了洗衣系统的吞吐率（throughput)。因此，流水线不会缩短洗一次衣服的时间，但是当有很多衣物需要洗时，吞吐率的提高减少了完成整个任务的时间。

如果每个步骤需要的时间相同，并且要完成的工作足够多，那么由流水线产生的加速比等于流水线中步骤的数目，在这个例子中是4倍：洗涤、烘干、折叠和收起。因此，流水线方式洗衣是非流水线方式洗衣速度的4倍：流水线中20次洗衣需要的时间是一次洗衣的5倍，而20次非流水线洗衣的时间是一次洗衣的20倍。

同样的原则也可用于处理器，即采用流水线方式执行指令。RISC-V指令执行通常包含五个步骤：

1. 从存储器中取出指令。

2. 读寄存器并译码指令。

3. 执行操作或计算地址。

4. 访问数据存储器中的操作数（如有必要）。

5. 将结果写人寄存器（如有必要）。

因此，本章探讨的RISC-V流水线有五个阶段，正如流水线加速洗衣过程一样。

==== 面向流水线的指令系统设计

尽管上面的例子只是对流水线的简单介绍，但我们也能够通过它了解面向流水线设计的RISC-V指令系统。

第一，所有RISC-V指令长度相同。这个限制简化了流水线第一阶段取指令和第二阶段指令译码。在像x86这样的指令系统中，指令长度从1字节到15字节不等，流水线设计更具挑战性。现代x86架构在实现时，将x86指令转换为类似RISC-V指令的简单操作，然后流水化这些简单操作，而不是流水化原始的x86指令。

第二，RISC-V只有几种指令格式，源寄存器和目标寄存器字段的位置相同。

第三，存储器操作数只出现在RISC-V的load或store指令中。这个限制意味着可以利用执行阶段来计算存储器地址，然后在下一阶段访问存储器。如果可以操作内存中的操作数，就像在x86中一样，那么第三阶段和第四阶段将扩展为地址计算阶段、存储器访问阶段和执行阶段。

==== 流水线数据通路和控制

下图显示了4.4节中提到的单周期数据通路，并且标识了流水线阶段。将指令划分成五个阶段意味着五级流水线，还意味着在任意单时钟周期里最多执行五条指令。相应的，我们必须将数据通路划分成五个部分，将每个部分用对应的指令执行阶段来命名：

1. IF：取指令

2. ID：指令译码和读寄存器堆

3. EX：执行或计算地址

4. MEM：存储器访问

5. WB：写回

在下图中，这五个部分与图中数据通路的绘制方式是对应的，指令和数据通常随着执行过程从左到右依次通过这五个阶段。再回到我们的洗衣类比，在通过工作线路时衣服依次被清洁、烘干和整理，同时永远不会逆向移动。然而，在从左到右的指令流动过程中存在两个特殊情况：在写回阶段，它将结果写回位于数据通路中段的寄存器堆中。在选择下一PC值时，在自增PC值与MEM阶段的分支地址之间进行选择。从右到左的数据流向不会对当前的指令造成影响，这种反向的数据流动只会影响流水线中的后续指令。需要注意的是，第一种特殊情况会导致数据冒险，第二种会导致控制冒险。

TIP: p206

我们可以通过引入寄存器保存数据的方式，使得部分数据通路可以在指令执行的过程中被共享。

举例来说，指令存储器只在指令的五个阶段中的一个阶段被使用，而在其他四个阶段中允许被其他指令共享。为了保留在其他四个阶段中的指令的值，必须把从指令存储器中读取的数据保存在寄存器中。类似的理由适用于每个流水线阶段，所以我们必荣将寄存器放置在上图中每个阶段之间的分隔线上。再回到洗衣例子中，我们会在每两个步骤之间放置一个篮子，用于存放为下一步所准备的衣服。

下图显示了流水线数据通路，其中的流水线寄存器被高亮表示。所有指令都会在每一个时钟周期里从一个流水线寄存器前进到下一个寄存器中。寄存器的名称由两个被该寄存器分开的阶段的名称来命名。例如，F和ID阶段之间的流水线寄存器被命名为IF/D。

TIP: p207

需要注意的是，在写回阶段的最后没有流水线寄存器。所有的指令都必须更新处理器中的某些状态，如寄存器堆、存储器或PC等、因此、单独的流水线寄存器对于已经被更新的状态来说是多余的。例如，加载指令将它的结果放人32个寄存器中的一个，此后任何需要该数据的指令只需要简单地读取相应的寄存器即可。

当然，每条指令都会更新PC，无论是通过自增还是通过将其设置为分支目标地址。PC可以被看作一个流水线寄存器：它给流水线的F阶段提供数据。不同于上图中被标记阴影的流水线寄存器，PC是可见体系结构状态的一部分，在发生例外时，PC中的内容必须被保存，而流水线寄存器中的内容则可以被丢弃。在洗衣的例子中，你可以将PC看作在清步骤之前盛放脏衣服的篮子。

==== 利用指令级并行的基本编译器技术

- 找出除维护循环的代码外互不相关的循环迭代，判定循环展开是有用的。

- 使用不同寄存器，以避免由于不同运算使用相同寄存器而造成的非必要约束（比如，名称依赖）。

- 去除多余的测试和分支指令，并调整循环终止与迭代代码。

- 通过观察不同迭代中的载人指令与存储指令互不相关，判定展开后的循环中的载人指令和存储指令可以交换位置。这一变换需要分析存储器地址，确认它们没有引用同一地址。

- 在保留必要的依赖，以得到与原代码相同的结果的前提下，对代码进行调度。

要进行所有这些变换，关键是要理解指令之间的依赖关系，而且要知道在这些关系下如何改变指令或调整指令的顺序。

有3种效果会限制循环展开带来的好处：

1. 每次展开操作分摊的开销降低；

2. 代码规模限制;

3. 编译器限制。

我们首先考虑循环开销问题。将循环展开4次时，它在指令之间产生了足够的并行性，可以在没有停顿周期的情况下调度循环。事实上，在14个时钟周期中，只有2个周期是循环开销：维护索引值的addt和终止循环的bne。如果将循环展开8次，这一开销将从每个元素1/2周期降低到1/4周期。

展开的第二个限制是代码规模的增长。对于较大规模的循环，代码规模的增长可能是一个问题，特别是当它会导致指令缓存缺失率上升时。

还有一个通常比代码规模更重要的因素，就是由于大量进行展开和调度而造成寄存器数量不足。由于在大段代码中进行指令调度而产生的这一副作用被称为寄存器紧缺（register pressure）。之所以会出现这种情况，是因为调度代码以增加IP时导致存活值的数量增加。在大量进行指令调度之后，可能无法将所有存活值都分配到寄存器中。尽管转换后的代码在理论上运行速度更快，但由于它会造成寄存器紧缺，所以可能会损失部分乃至全部收益。在没有展开循环时，分支就足以限制大量使用调度，所以寄存器紧缺几乎不会成为问题。但是，循环展开与大量调度结合起来却可能导致这一问题。在需要暴露更多独立指令序列的多发射处理器中，这个问题变得尤其具有挑战性，因为这些指令序列的执行可能是重叠的。一般来说，高级、复杂转换的应用导致现代编译器的复杂度大幅增加，而在生成具体代码之前，很难度量这种应用带来的可能提升。

循环展开是一种简单但有用的方法，能够增大可以有效调度的直线代码片段的规模。这种转换在各种处理器上都非常有用，从前面研究过的简单流水线，到多发射超标量，再到本章后面要研究的VLIW。

=== 冒险与竞争

[options="header"]
|====
|冒险类型|原因|解决方案

|结构冒险
|硬件不支持多条指令在同一时钟周期执行
|可以在设计流水线时避免

|数据冒险
|一个指令必须等待其他指令的结果才能完成导致的停顿为数据冒险
|采用前递或旁路、动态调度技术优化

|控制冒险
|在分支判断结果未出现时，无法得知下一条指令是什么，导致停顿
|采用分支预测技术优化

|====

==== 结构冒险

硬件不支持多条指令在同一时钟周期执行。在洗衣例子中，如果用洗衣烘干一体机而不是分开的洗衣机和烘干机，或者如果你的室友正在做其他事情而不能收好衣服，都会发生结构冒险。这时，我们精心设计的流水线就会受到破坏。如上所述，RISC-V指令系统是面向流水线设计的，这使得设计人员在设计流水线时很容易避免结构冒险。

==== 数据冒险

假设你在叠衣服时发现一只袜子找不到与之匹配的另一只。一种可能的策略是跑到房间，在衣橱中找，看是否能找到另一只。显然，当你在找袜子时，完成烘干准备被折叠的衣服和那些已经洗完准备去烘干的衣服，不得不停顿等待。在计算机流水线中，数据冒险源于一条指令依赖于前面一条尚在流水线中的指令(这种关系在洗衣例子中并不存在)。

例如，假设有一条加法指令，它后面紧跟着一条使用加法的和的减法指令(x19)：

[source,asm]
----
add x19, x0, x1

sub x2, x19, ×3
----

在不做任何干预的情况下，这一数据冒险会严重地阻碍流水线。add指令直到第五个阶段才写结果，这将浪费三个时钟周期。尽管可以尝试通过编译器来消除这些冒险，但结果并不令人满意。这些依赖经常发生，并且导致的延迟太长，所以不可能指望编译器将我们从这个困境中解救出来一种基本的解决方案是基于以下发现：不需要等待指令完成就可以尝试解决数据冒险。对于上面的代码序列，一旦ALU计算出加法的和，就可将其作为减法的输入。向内部资源添加额外的硬件以尽快找到缺少的运算项的方法，称为前递（forwarding）或旁路(bypassing)

前递的效果很好，但不能避免所有的流水线停顿。有时候即使使用前递，流水线也不得不停顿一个阶段来处理载入-使用型数据冒险（load-use data hazard），如下图所示。该图包含流水线的一个重要概念，正式叫法是流水线停顿（pipeline stall），但通常俗称为气泡（bubble）。

TIP: 图

当一条load指令之后紧跟着一条需要使用其结果的R型指令时，即使使用前递也需要停顿。如果不停顿，从存储器访问阶段的输出到执行阶段的输入这条路径意味着时间倒流，这是不可能的。该图实际是一个示意图，因为直到sub指令被取出并译码后才知道是否需要停顿。

==== 用动态调度克服数据冒险

除非是流水线中的已有指令与要读取的指令之间存在数据依赖，而且无法通过旁路或前递来隐藏这一数据依赖，否则，简单的静态调度流水线就会提取一条指令并发射出去。（前递逻辑可以减少实际流水线延迟，所以某些依赖不会导致冒险。）如果存在不能隐藏的数据依赖，那么冒险检测硬件会从使用该结果的指令开始，将流水线置于停顿状态。在清除这一依赖之前，不会提取和发射新的指令。

在动态调度中，硬件会重新安排指令的执行顺序以减少停顿，同时保持数据流和异常行为。动态调度有几个优点:

第一，它允许针对一种流水线编译的代码在不同类型的流水线上高效执行，不需要多个二进制文件，也无须为不同的微体系结构重新速行编译。如今，大多数软件来自第三方，而且是以二进制文件形式分发的，这种计算环境使上述优势更加明显。

第二，它可以应对编译时依赖关系未知的情况；比如，这些依赖可能涉及存储器访问或者与数据有关的分支，或者，它们可能源自使用动态链接或动态分发的现代编程环境。

第三，也可能是最重要的一个优点，它允许处理器容忍一些预料之外的延迟，比如缓存缺失，它可以在等待解决缺失问题时执行其他代码。

尽管动态调度的处理器不能改变数据流，但它会在存在依赖关系时尽力避免停顿。相反，由编译器调度的静态流水线尽量将停顿时间降至最低，具体方法是隔离相关指令，使它们不会导致骨险。当然，对于那些本来准备在采用动态调度流水线的处理器上运行的代码，也可以使用编译器流水线调度。

简单流水线技术的一个主要限制是，它们使用顺序指令发射与执行：指令按程序顺序发射；如果一条指令停顿在流水线中，后续指令都不能执行。因此，如果流水线中两条相距很近的指令存在依赖关系，就会导致冒险和停顿。如果存在多个功能单元，这些单元也可能处于空闲状态。如果指令j依赖于长时间运行的指令i（当前正在流水线中执行），那么j之后的所有指令都必须停顿，直到i完成、j可以执行为止。例如，考虑以下代码：
[source,asm]
----
fdiv.d f0.12.f4

fadd.d f10.f0.r8

fsub.d f12.f8.f14
----

由于fadd.d对fdiv.d的依赖性会导致流水线停顿，所以fsub.d指令不能执行；但是，fsub.d与流水线中的任何指令都没有数据依赖性。这一冒险会对性能造成限制，如果不需要以程序顺序来执行指令，就可以消除这一限制。

在经典的五级流水线中，可在指令译码（ID）期间检查结构冒险和数据冒险：当一个指令可以无冒险执行时，它会从ID发射出去，并确认所有数据冒险都已解决。

为了能够开始执行上面例子中的fsub.d，必须将发射过程分为两个部分：检查所有结构胃险和等待数据冒险的消失。因此，我们仍然使用顺序指令发射（即按程序顺序发射指令），但我们希望一条指令能够在其数据操作数可用时立即开始执行。这样的流水线实际是乱序执行(out-of-order execution），这也就意味着乱序完成(out-of-order completion)。

乱序执行可能导致WAR冒险和WAW冒险，而这些冒险在这个五级整数流水线及其逻辑扩展中的顺序浮点流水线中是不存在的。考虑以下RISC-V浮点代码序列：
[source,asm]
----
fdiv.d f0.f2.f4

fmul.d f6.f0.f8

fadd.d f0.f10.f14
----

在fmul.d和fadd.d之间存在反依赖（对于寄存器f0），如果流水线在fmul.d（在等待fdiv.d)之前执行fadd.d，将会违反反依赖性，产生WAR冒险。与此类似，为了避免违反输出依赖，比如由fadd.d在fdiv.d完成之前写入f0，就必须处理WAW冒险。后面将会看到，利用寄存器重命名可以避免这两种冒险。

乱序完成还会使异常处理变得复杂。采用乱序完成的动态调度必须保留异常行为，使那些在严格按照程序顺序执行程序时会发生的异常仍然会实际发生，并且不会发生其他异常。动态调度的处理器会通过推迟相关异常的发布来保留异常行为，直到处理器知道该指令就是接下来要完成的指令为止。

尽管异常行为必须保留，但动态调度的处理器可能造成非精确异常。如果在发生异常时，处理器的状态与严格按照程序顺序执行指令时的状态不完全一致，就说这一异常是非精确的。非精确异常可以因为以下两种可能性而发生:

1. 流水线在执行导致异常的指令时，可能已经完成了按照程序顺序排在这一指令之后的指令。

2. 流水线在执行导致异常的指令时，可能还没有完成按照程序顺序排在这一指令之前的指令。

非精确异常增大了在异常之后重新开始执行的难度。我们在这一节不会解决这些问题，而是讨论一种解决方案，这种方案能够在具有推测功能的处理器环境中提供精确异常。

为了能够进行乱序执行，我们将五级简单流水线的ID流水级大体分为以下两个阶段:

1. 发射（issue）——指令译码，检查结构冒险。

2. 读取操作数——一直等到没有数据冒险后，然后读取操作数。

指令读取阶段在发射阶段之前，既可以把指令放到指令寄存器中，也可能放到一个待完成指令队列中，然后从指令寄存器或队列发射这些指令。执行阶段跟在读取操作数阶段之后，这一点和五级流水线中一样。执行过程可能需要多个周期，具体数目取决于所执行的操作。

我们区分一个指令开始执行和完成执行的时刻，在这两个时刻之间，指令处于执行过程中。我们的流水线允许同时执行多条指令，如果没有这一功能，就会失去动态调度的主要优势。要同时执行多条指令，需要有多个功能单元或流水化功能单元，或者两者兼有。由于这两种功能（流水化功能单元和多个功能单元）在流水线控制方面大体相当，所以我们假定处理器拥有多个功能单元。

在动态调度流水线中，所有指令都顺序经历发射阶段（顺序发射）；但是，它们可能在第二阶段（读取操作数阶段）停顿或者相互旁路，从而进人乱序执行状态。记分牌（scoreboarding）技术允许在有足够资源且不存在数据依赖时乱序执行指令。它的名字源于开创了这项技术的CDC600记分牌。还有一个比较重要的算法为Tomasulo 算法。它们之间的主要区别在于，Tomasulo算法通过对寄存器进行有效的动态重命名来处理反依赖和输出依赖。此外。还可以对Tomasulo算法进行扩展，用来处理推测，这种技术通过预测一个分支的输出、执行预则目标地址的指令、在预测错误时采取纠正措施，降低控制依赖的影响。虽然使用记分牌可能足以支持简单的处理器，但更复杂、更高性能的处理器则要利用推测技术。

TIP: Tomasulo算法介绍？

==== 控制冒险

控制冒险出现在以下情况：需要根据一条指令的结果做出决定，而其他指令正在执行。

假设洗衣店的工作人员接到一个令人高兴的任务：清洁足球队队服。根据衣服的污浊程度，需要确定清洗剂的用量和水温设置是否合适，以致能洗净衣物又不会由于清洗剂过量而磨损衣物。在洗衣流水线中，必须等到第二步结束，检查已经烘干的衣服，才知道是否需要改变洗衣机设置。这种情况该怎么办？

有两种办法可以解决洗衣问题中的控制冒险，也适用于计算机中的相同问题，以下是第一种办法。

停顿：第一批衣物被烘干之前，按顺序操作，并且重复这一过程直到找到正确的洗衣设置为止。这种保守的方法当然有效，但速度很慢。计算机中相同的问题是条件分支指令。请注意，在取出分支指令后，紧跟着在下一个时钟周期就会取下一条指令。但是流水线并不知道下一条指令应该是什么，因为它刚刚从存储器中取出分支指令！就像洗衣问题一样，一种可能的解决方案是在取出分支指令后立即停顿，一直等到流水线确定分支指令的结果并知道要从哪个地址取下一条指令为止。

对于较长的流水线，通常无法在第二阶段解决分支指令的问题，那么每个条件分支指令都停顿，将导致更严重的速度下降。由此产生了解决控制冒险的第二个方法：

预测：如果你确定清洗队服的设置是正确的，就预测它可以工作，那么在等待第一批衣服被烘干的同时清洗第二批衣服。如果预测正确，这个方法不会减慢流水线。但是如果预测错误，就需要重新清洗做预测时所清洗的那些衣服。

计算机确实采用预测来处理条件分支。一种简单的方法是总是预测条件分支指令不发生跳转。如果预测正确，流水线将全速前进。只有条件分支指令发生跳转时，流水线才会停顿。更成熟的分支预测是预测一些条件分支指令发生跳转，而另一些不发生跳转。在洗衣的类比中，夜晚和主场比赛的队服采用一种洗衣设置，而白天和客场比赛的队服则采用另一种设置。在计算机程序中，循环底部是条件分支指令，并会跳转回到循环的顶部。由于它们很可能发生分支并且向回跳转，所以可以预测发生分支并跳到靠前的地址处。

这种分支预测方法依赖于始终不变的行为，没有考虑到特定分支指令的特点。与之形成鲜明对比的是，动态硬件预测器根据每个条件分支指令的行为进行预测，并在程序生命周期内可能改变条件分支的预测结果。对于洗衣例子，使用动态预测方法，一名店员查看队服的污程度并预测洗衣设置，同时根据最近的成功预测调整下一次的题测。动态预测的一种常用实现方法是保存每个条件分支是否发生分支的历史记录，然后根据最近的过去行为来预测未来。历史记录的数量和类型足够多时，动态分支预测器的正确率超过90%。当预测错误时，流水线控制必须确保预测错误的条件分支指令之后的指令执行不会生效，并且必须从正确的分支地址处重新启动流水线。在洗衣例子中，必须停止接受新的任务，以便可以重新启动预测错误的任务如同其他解决冒险的方案一样，较长的流水线会恶化预测的性能，并增加预测错误的代价。

TIP: 量化p141 高级分支预测

=== 例外

控制逻辑是处理器设计中最有挑战的部分：验证正确性最为困难，同时也最难进行时序优化。例外（cexception）和中断（interupt）是控制逻辑需要实现的任务之一。除分支指令外，它是另一种改变指令执行控制流的方式。最初，人们使用它们是为了处理CPU内部的意外事件，例如未定义指令。后续经扩展也可处理与CPU进行通信的LO设备。

许多体系结构设计者和相关书籍作者并不区分中断和例外，经常使用其中一种同时指代两者。比如，Intelx86中就是使用中断。在本书中，我们使用例外来指代意外的控制流变化，而这些变化无须区分产生原因是来自于处理器内部还是外部；使用中断仅仅指代由处理器外部事件引发的控制流变化。下表是一些示例，包括例外的类型、引发例外的事件来源以及在RISC-V体系结构中的表示。

[options="header"]
|====
|事件类型|例外来源|RISC-V中的表示

|系统重启
|外部
|例外

|I/O设备请求
|外部
|中断

|用户程序进行操作系统调用
|内部
|例外

|未定义指令
|内部
|例外

|硬件故障
|皆可
|皆可
|====

通常，检测和处理例外的控制逻辑会处于处理器的时序关键路径上，这对处理器时钟频率和性能都会产生重要影响。如果对控制逻辑中的例外处理不给予充分重视，一旦尝试在复杂设计中添加例外处理，将会明显降低处理器的性能。这和处理器验证一样复杂

==== RISC-V体系结构中如何处理例外

在目前所讲过的实现中，只存在两种例外类型：未定义指令和硬件故障。例如，假设在指令add x1, x2, x1执行时出现硬件放障。当例外发生时，处理器必须执行的基本动作是：在系烧例外程序计数器(Supervisor Exception Program Counter,SEPC)中保存发生例外的指令地址，同时将控制权转交给操作系统。

之后，操作系统将做出相应动作，包括为用户程序提供系统服务，硬件故障时执行预先定义好的操作，或者停止当前程序的执行并报告错误。完成例外处理的所有操作后，操作系统使用SEPC寄存器中的内容重启程序的正常执行。可能是继续执行原程序，也可能是终止程序。

操作系统进行例外处理，除了引发例外的指令外，还必须获得例外发生的原因。目前使用两种方法来通知操作系统。RISC-V中使用的方法是设置系统例外原因寄存器（SupervisorExcption Cause Register. SCAUSE)，该寄存器中记录了例外原因。

另一种方法是使用向量式中断(vectored intecrupt)。该方法用基址寄存器加上例外原因（作为偏移）作为目标地址来完成控制流转换。基址寄存器中保存了向量式中断内存区域的起始地址。

操作系统可根据例外向量起始地址来确定例外原因。如果不使用此种方法，如RISC-V，就需要为所有例外提供统一的入口地址，由操作系统解析状态寄存器来确定例外原因。对于使用向量式例外的设计者，每个例外入口需要提供比如32字节或8条指令大小的区域，供操作系统记录例外原因并进行简单处理。通过添加一些额外寄存器和控制信号，并稍微扩展控制逻辑，就可以完成对各种例外的处理。

==== 流水线实现中的例外

流水线实现中，将例外处理看成另一种控制冒险。例如，假设add指令执行时产生硬件故障。正如之前章节中处理发生跳转的分支一样，我们需要在流水线上清除掉add之后的指令，并从新地址开始取指。和处理分支指令不同的是，例外会引起系统状态的变化。

处理分支预测错误时，我们将取指阶段的指令变为空操作（nop），以此来消除影响。对于进入译码阶段的指令，增加新逻辑控制译码阶段的多选器使输出为0，流水线停顿。添加一个新的控制信号ID.Flush，它与来自于冒险检测单元的stall信号进行或（OR）操作。使用该信号对进入译码阶段的指令进行清除。对于进入执行阶段的指令，我们使用一个新的控制信号EX.Flush，使得多选器输出为0。RISC-V体系结构中使用0000 00001C09 00001作为例外入口地址。为保证从正确地址开始取指，我们为PC多选器新增一个输入，保证能将上述例外入口地址送给PC寄存器。

上述例子指出了例外处理需要注意的一个问题：如果我们在add指令执行完毕后检测例外，程序员将无法获得xl寄存器中的原值，因为它已更新为add指令的执行结果。如果我们在add指令的EX阶段检测例外，可以使用EX.Flush信号去避免该指令在WB阶段更新寄存器。有一些例外类型，需要最终完成引发例外的指令的执行。最简单的方法就是清除掉该指令，并在例外处理结束后从该指令重新开始执行。

最后一步是，在SEPC寄存器中保存引发例外的指令的地址。

=== 指令间的并行性

编译器或处理器来猜测指令的行为并提前开始执行。如果猜测正确则进行指令提交，错误则清除结果并从执行正确的指令。

- 推测的概念

- 基于硬件的推测

- 以多发射和静态调度来利用指令级并行

- 以动态调度、多发射和推测来利用指令级并行

- 用于指令交付和推测的高级技术

流水线技术挖掘了指令间潜在的并行性，这种并行性被称为指令级并行（ILP）。提高指令级并行度主要有两种方法。

1. 增加流水线的级数，让更多的指令重叠执行

	仍然使用上文提到的洗衣店进行类比。假设洗衣阶段所需时间比其他阶段都长，我们可以将洗衣阶段再细分为洗涤、漂洗和甩干三个阶段。这样就将一个四级流水线变为六级流水线。不论是处理器还是洗衣店，如需获得最高加速比，还要重新调整其他阶段的时长至相等来平衡流水线。加深流水线后，由于有更多的操作可以重叠执行，指令间的并行度更高。同时，时钟周期变短，主频变高，处理器性能也就更高。
	
2. 增加流水线内部的功能部件数量，这样可以每周期发出多条指令

	这种技术被称为多发射(multiple issue)。一个拥有三个洗衣机和三个烘干机的多发射洗衣店代替了之前的家庭式洗衣机和烘干机。也许你还需要招聘一些助手来折叠和收纳，这样被能在相同时间内完成之前的三倍工作量。唯一的缺点在于，需要在相邻流水阶段之间传递伤载，并保证所有机器都满负荷工作，这增加了额外的工作量。
	
每周期发射多条指令，使得指令执行频率可以超过时钟频率。换句话来说，就是CPI可以小于1。举例，一个主频为3GHz、发射宽度为4的多发射处理器，峰值速度为每秒执行120亿条指令，理论上CPI为0.25，或IPC为4。如果这是一个五级流水的处理器那么同一时间内流水线中最多会有20条指令在执行。目前高端处理器的发射宽度为每周期3~6条指令，普通处理器的发射宽度一般为2。不过，多发射技术会有一些限制，例如哪些指令可以同时执行、如果发生冒险如何处理等。

实现多发射处理器主要有两种方法，区别在于编译器和硬件的不同分工。如果指令发射与否的判断是在编译时完成的，称为静态多发射（static multiple issue）。如果指令发射与否的判断是在动态执行过程中由硬件完成的，称为动态多发射(dynamic multiple issue)。这两个方法可能还有其他一些名称，但都不够准确或限制过严。

在多发射流水线中，需要处理如下两个主要任务：

1.将指令打包并放入发射槽。处理器如何判断本周期发射多少条指令?发射哪些指令？在大多数静态发射处理器中，编译器会完成这部分工作。而在动态发射处理器中，这部分工作通常会在运行时由硬件自动完成，编译器可以通过指令调度来提高发射效率。

2.处理数据和控制冒险。在静态发射处理器中，编译器静态处理了部分或所有指令序列中存在的数据和控制冒险。相应的，大多数动态发射处理器是在执行过程中使用硬件技术来解决部分或所有类型的冒险。

TIP: 静态多发射、动态多发射?

<<<