== 计算机概论与设计分析基础

TIP: 为表格与图片标记序号并在正文中引用

=== 引言

=== 计算机的分类

1. 物联网/嵌入式计算机

	物联网/嵌入式计算机是一种专门为特定功能设计的计算机系统，通常嵌入到更大的设备或系统中，以实现专用的任务。这类计算机通常具备低功耗、小体积和高可靠性的特点。它们硬件资源有限，通常运行轻量级的实时操作系统或者无操作系统，专注于单一或少量功能的高效执行。嵌入式计算机广泛应用于智能家居设备（如智能音箱、恒温器）、工业控制系统（如PLC）、汽车电子（如自动驾驶辅助系统）、医疗设备（如便携式医疗监测设备）等场景中。树莓派、ESP32、Arduino等设备是这一领域的典型代表。

2. 个人移动设备

	个人移动设备是为便携性设计的小型计算设备，如智能手机、平板电脑和智能手表。它们集成了触控屏幕、摄像头、麦克风等多种输入输出设备，通常运行移动操作系统（如Android或iOS），支持多任务处理。个人移动设备的特点是设计轻薄便携，具有无线连接能力（如Wi-Fi、蜂窝网络）以及较长的电池续航时间。这类设备已经成为现代人生活的核心工具，广泛用于通信（如电话、视频通话）、娱乐（如游戏、音乐、视频）、工作（如电子邮件、文档处理）和导航等场景。智能手机是最常见的个人移动设备，平板电脑和智能手表则进一步扩展了其使用范围。

3. 桌面计算机

	桌面计算机是一种固定式个人计算机，通常由主机、显示器、键盘和鼠标组成，适合放置在工作台上。其特点是性能强大、散热能力优越，可扩展性强，硬件组件（如内存、存储、显卡等）可以根据需要进行更换和升级。桌面计算机主要用于高性能任务，如办公应用（文档处理、数据分析）、高性能游戏、内容创作（视频剪辑、图形设计）、编程开发等。相比于笔记本电脑，桌面计算机更适合需要长期使用或性能要求较高的场景。常见的品牌台式机如戴尔OptiPlex，DIY装机则提供了更大的灵活

4. 服务器

	服务器是一种专门为提供服务设计的高性能计算机，通常位于数据中心，为其他计算机或用户提供计算、存储和网络服务。服务器的特点是性能强劲、稳定可靠，支持多线程、多任务处理，并具备冗余设计（如双电源、ECC内存）以确保高可用性。它们通过专用的硬件和软件（如虚拟化技术）来实现远程管理和资源共享。服务器被广泛应用于托管网站（Web服务器）、运行数据库（数据库服务器）、支持网络通信（邮件服务器、DNS服务器）以及提供云计算服务等场景。典型的服务器设备包括刀片式服务器（如Dell PowerEdge）和机架式服务器（如HPE ProLiant）。

5. 分布式集群（计算机）

	分布式集群是一种由多台计算机通过网络连接组成的计算系统，这些计算机协同工作，共同完成复杂任务。它的特点是高可扩展性，可以通过增加计算节点提升系统性能，同时具备高容错性，部分节点故障不会影响整体运行。分布式集群通常采用资源共享的方式，将任务分配到各个节点进行并行处理。它广泛应用于高性能计算（如科学模拟、基因分析）、大数据处理（如Hadoop和Spark平台）、云服务（如AWS和Google Cloud）以及分布式存储（如Ceph和HDFS）。超级计算机（如Fugaku）和云计算集群（如Kubernetes）是分布式集群的重要代表。

=== 计算机的组成

==== 硬件组成部分

1. 输入设备

	输入设备是计算机硬件的重要组成部分，用于将外部信息转换为计算机能够识别和处理的电子信号。这些设备通常负责捕捉用户的指令或环境中的数据，以便计算机能够执行相应的操作。常见的输入设备包括键盘、鼠标、触摸屏、麦克风、摄像头以及传感器等。它们的主要特点是多样化和精确性，例如键盘适合精确输入文本和命令，而麦克风可以捕捉声音信号以供语音识别和通信使用。输入设备广泛应用于各类场景，从办公和游戏到自动化监控和虚拟现实体验，为计算机与用户之间的交互提供了多种可能性。

2. 输出设备

	输出设备是计算机将处理结果以用户可感知形式输出的硬件部分。它们的主要作用是将计算机内部的数字信息转换为可视、可听或其他形式的表现，以便用户理解和利用。常见的输出设备包括显示器、打印机、扬声器、耳机以及触觉反馈设备等。输出设备的特点在于提供高质量的表现形式，例如高分辨率显示器可以展现清晰的图像和视频，扬声器可以播放高保真的音频内容。这些设备在日常生活、专业工作和娱乐中应用广泛，例如在设计领域显示高分辨率的图像，在教育领域播放多媒体内容，以及在虚拟现实中提供多感官的沉浸式体验。

3. 储存器

	储存器是计算机用于保存数据和程序的硬件部件，分为不同层次以满足性能与容量需求的平衡。层次化存储的结构通常包括高速缓存（Cache）、主存（RAM）和外存（如硬盘、固态硬盘）。高速缓存存储常用数据，具有低延迟、高速度的特点；主存作为计算机的工作内存，支持快速读写；外存则负责长期保存大量数据。储存器的层次化设计通过不同级别的速度和容量优化了计算机系统的性能与成本。储存器的广泛应用包括在游戏中提供快速加载、在数据中心存储海量信息，以及在嵌入式设备中保存操作程序和运行时数据。

4. 运算器

	运算器是计算机执行算术和逻辑运算的核心部件，通常由加法器、逻辑单元和寄存器等组成。其主要功能是处理指令中的计算任务，包括整数运算、浮点运算和逻辑判断等。运算器的特点在于速度和精确性，它能够在短时间内完成复杂的数学运算，并为其他硬件提供支持。现代运算器通常集成在处理器中，通过并行计算技术进一步提升性能。运算器广泛应用于科学计算、图形渲染、加密解密以及人工智能模型训练等领域，是计算机完成复杂任务的基础硬件。

5. 控制器

	控制器是计算机的指挥中心，用于解析并执行指令，协调其他硬件部件的工作。控制器通过时钟信号驱动整个系统，并负责管理指令的获取、解码和执行过程。现代控制器与运算器一起构成了处理器（CPU），具备更高的集成度和性能。控制器支持多种并行技术，包括指令级并行（同时执行多条指令）、数据级并行（对大规模数据并行操作）以及线程级并行（同时运行多个任务）。这些特点使控制器能够处理多样化和复杂的任务。控制器的应用涵盖了从日常计算到高性能计算领域，如图像处理、多线程编程以及虚拟化平台支持，是现代计算系统的核心。

==== 软件组成部分

1. 应用软件

	应用软件是专门为用户完成特定任务而开发的软件，直接服务于用户的需求。它的定义涵盖了从单一功能工具到综合型解决方案的广泛范围，例如文字处理软件、图形设计工具、会计软件、社交媒体应用等。应用软件的特点是面向用户需求设计，界面友好，功能明确，并能够在各种设备和平台上运行，如桌面计算机、移动设备和云平台。应用软件在日常生活和工作中应用广泛，例如在办公场景中使用Microsoft Office进行文档处理，在娱乐领域通过媒体播放器观看电影，在专业领域利用AutoCAD进行工程设计，以及在电子商务平台上进行购物和交易。应用软件的种类和功能随着用户需求的变化而不断丰富。

2. 系统软件

	系统软件是计算机运行的基础，主要负责管理硬件资源并为应用软件提供支持和运行环境。它包括操作系统（如Windows、Linux、macOS）、驱动程序、系统工具和基础库等。系统软件的特点是抽象复杂硬件操作，提供标准化接口，确保硬件资源的高效分配和安全管理。它通常以后台运行的方式为用户和应用软件提供服务。操作系统是系统软件的核心部分，负责内存管理、文件系统、进程调度和设备管理等功能。此外，系统软件的可靠性和性能对整个计算机系统的稳定性至关重要。它广泛应用于个人电脑、服务器、移动设备以及嵌入式系统中，为用户的高效使用提供保障，同时也为应用软件开发者提供了统一的平台。

=== 计算机体系结构

计算机体系结构包含计算机的物理实现及其逻辑设计（硬件）、各个部件之间的互连（组成，也称为微体系结构）。

==== 七个伟大思想

[options="header"]
|=======================
|思想 |概括
|使用抽象简化设计|通过隐藏底层细节，专注于高层设计逻辑，从而简化复杂系统的开发。这一思想类似于函数的使用：函数封装了具体的实现逻辑，对外提供统一的接口，使得开发者可以专注于高层结构设计，而无需了解底层实现细节。应用场景包括模块化编程、操作系统的虚拟内存管理以及软件工程中的面向对象设计。
|加速经常性事件|针对系统中常见的操作进行优化，使其运行得更快、更高效。这一思想基于“常见情形出现得更频繁”这一观察，例如处理器优化分支预测的命中路径或缓存对热点数据的快速访问。这种方法使得系统能将资源优先分配给高频事件，从而整体提升性能。
|通过并行提高性能|通过指令级并行（如流水线技术）、数据级并行（如向量体系结构和GPU）、线程级并行（如多核处理器）来提高系统性能。并行化是现代计算机设计中的核心理念之一，其目的是充分利用硬件资源，在多个层次上同时处理数据和指令。例如，GPU擅长数据级并行，在图形处理和深度学习中具有极高效率。
|通过流水线提高性能|流水线技术是一种指令级并行实现方式，它将指令分解为多个阶段，各阶段可以同时处理不同的指令部分，从而提高吞吐量。这种方法类似于工业生产线，将复杂任务分解为多个子任务，各个子任务可以并行执行。应用于处理器设计中，流水线技术显著提升了指令执行的效率。
|通过预测提高性能|分支预测是一种提高性能的技术，通过提前执行可能的分支路径来减少因条件分支而造成的停顿。当预测结果正确时，性能显著提升；如果预测错误，系统则会撤回无效的操作。这一技术广泛用于现代处理器中，以减少分支指令对流水线的干扰。
|储存层次|存储层次结构是通过缓存机制和虚拟存储来优化数据访问速度的一种设计思想。系统将经常使用的数据存储在较快的存储层（如缓存）中，而将较少访问的数据存储在容量较大的层（如磁盘）中。这种机制通过权衡存取速度和存储容量，提升了整体性能。
|通过冗余提高可靠性|冗余设计在系统中增加了额外的组件或信息，用于在发生故障时代替失效部分，从而保持系统的正常运行。例如，RAID存储技术通过冗余磁盘阵列来保护数据安全，冗余电源设计确保即使单个电源失效，系统仍能正常运行。这种方法提升了系统的容错性和可靠性。
|=======================

=== 计算机的性能

计算机处于不同场景下对于性能的关注点不一样，如个人用户更关注计算机的响应时间，而服务器更关心它的吞吐量与带宽。对于性能好坏的评价在不同场景下需要使用不同的标准。

==== 性能的定义与度量

时间是计算机性能的衡量标准

[options="header"]
|=======================
|时间的定义|内容
|响应时间|响应时间指的是完成某项任务所需的总时间，包括所有相关开销。这不仅仅是CPU执行任务的时间，还包含等待I/O操作的时间、内存访问时间以及操作系统调度时间等。响应时间通常用于衡量系统的整体性能，特别是在实时系统或交互式应用中。例如，当用户点击一个网页链接，响应时间指从点击开始到页面完全加载并呈现的总时间。优化响应时间可以提升用户体验，其关键策略包括优化I/O性能、减少系统开销以及提升任务调度的效率。
|CPU执行时间|CPU执行时间是指程序在CPU上实际执行指令所花费的时间，通常细分为用户CPU时间和系统CPU时间。用户CPU时间是程序运行其自身代码所用的时间，而系统CPU时间则是操作系统为该程序提供服务所用的时间（如处理系统调用）。CPU执行时间通常被用来评估程序的计算效率，与响应时间不同，它忽略了外部因素的干扰（如I/O等待）。程序员可以通过优化算法、减少上下文切换以及充分利用硬件资源（如向量化和多线程）来减少CPU执行时间。
|时钟周期数|时钟周期数是衡量计算机硬件完成基本功能速度的指标，它表示某项操作所需的时钟周期总数。每个时钟周期由处理器的时钟频率定义，例如一个1 GHz的处理器的时钟周期为1纳秒。时钟周期数反映了指令执行的效率，是评估硬件性能的重要指标。通过减少每条指令所需的时钟周期数（CPI，Cycles Per Instruction）或提高处理器的时钟频率，可以提升计算性能。此外，现代处理器通过流水线和并行计算技术进一步优化时钟周期的利用率。
|=======================

==== CPU性能及其度量因素

[stem]
++++
程序的CPU执行时间 = 程序的CPU时钟数 \times 时钟周期时间
++++

由于时钟频率和时钟周期长度互为倒数，故另一种表达形式为：

[stem]
++++
程序的CPU执行时间 = \frac{程序的CPU时钟数}{时钟频率}
++++

这个公式表明，硬件设计者减少程序执行所需的CPU时钟周期数或缩短时钟周期长度。就能改进性能。

==== 指令性能

[stem]
++++
CPU时钟周期数 = 程序的指令数 \times 指令平均时钟周期数（CPI）
++++

CPI（Cycles Per Instruction）是指处理器平均执行一条指令所需的时钟周期数。它是衡量计算机处理器性能的重要指标之一，用于描述指令执行效率。公式如下：

[stem]
++++
CPI = \frac{总时钟周期数}{指令总数}
++++

CPI的大小反映了处理器执行指令的效率。较低的CPI表示处理器能够在更少的时钟周期内完成指令执行，而较高的CPI则意味着指令执行效率较低。CPI受多种因素影响，包括指令集架构、处理器的设计（如流水线深度、并行执行能力）以及指令的性质（简单指令和复杂指令的CPI可能差异较大）。CPI提供了一种相同指令系统在不同实现下比较性能的方法，因为在指令系统不变的情况下，一个程序执行的指令数是不变的。

==== 经典CPU性能公式

[stem]
++++
CPU时间 = 指令数 \times 指令平均时钟周期数（CPI）\times 时钟周期时间
++++

或：

[stem]
++++
CPU时间 = \frac{指令数 \times 指令平均时钟周期数（CPI）}{时钟周期时间}
++++

==== 性能的测量、报告和汇总

|===
.2+|基准测试 |桌面基准测试|处理器密集型测试、图形密集型测试
|服务器基准测试|事务处理基准测试
|性能测试结果 2+a|
[stem]
++++
SPECRatio = \frac{基准计算机上的执行时间}{待评估计算机上的执行时间}
++++
|===

- 处理器密集型测试

	主要关注处理器在执行大量计算任务时的效率。这种测试通常以数学运算、科学计算或加密算法为核心，测量处理器执行这些高计算强度任务的速度。它能够反映处理器的算术运算能力、指令执行效率以及寄存器操作的性能。处理器密集型测试广泛应用于高性能计算领域、科学研究以及对处理器进行性能对比分析。例如，使用基准工具如SPEC CPU基准套件来测试处理器在处理密集型任务时的表现，从而为用户或开发者选择硬件提供数据支持。

- 图形密集型测试

	主要用于评估系统在处理复杂图形任务时的能力，特别是显卡（GPU）的性能。这种测试通常通过渲染复杂的三维场景、光影效果和纹理操作，测量系统的帧率（FPS）、延迟和抗锯齿效果等指标。图形密集型测试反映了系统在游戏、视频渲染以及虚拟现实等场景中的性能表现。这类测试通常采用专业工具，例如3DMark、Unigine Heaven等，以模拟高负载图形任务的场景，从而判断显卡与驱动程序的综合性能。图形密集型测试对于游戏开发者、图形设计师和硬件厂商具有重要意义，能够帮助他们优化软件与硬件的兼容性和性能。

- 事务处理基准测试

	事务处理通常涉及大量的数据库操作，如插入、更新、查询以及删除数据，同时要求系统具备较高的并发处理能力和数据一致性。事务处理基准测试通常使用标准化的工作负载模型，如TPC-C（在线事务处理基准）或TPC-H（决策支持系统基准），来测量系统在多用户环境下的吞吐量、响应时间和扩展能力。这类测试广泛应用于企业信息管理、电子商务和金融服务领域，用以评估数据库管理系统、服务器和存储设备的性能，并为系统优化和扩展提供数据支持。

=== 计算机的发展方向

1. 技术上，由于摩尔定律的失效，缩小晶体管的尺寸与增加晶体管的数量越来越困难，需要从新材料新架构中寻求突破。另外，由于网络速度的加快，远程计算机、云服务将越来越实用与流行。

2. 能耗上，在移动设备与嵌入式设备（物联网）中，在低功耗的情况下实现高性能仍然是突破点

3. 芯片制造中，随着制程工艺的减少，芯片生产难度加大。改良制造工艺提高良率能有效降低成本

==== 技术趋势

TIP: 图

- 性能趋势：带宽胜过延迟

	带宽和吞吐量是指在给定时间内完成的总工作量，比如在进行磁盘读写时每秒传输的兆字节数。与之相对，延迟或响应时间是指一个事件从开始到完成所经过的时间，比如一次磁盘访问需要的毫秒数。在目前技术的发展过程中，带宽的改进速度超过延迟，而且这一趋势很可能持续下去。一个简单的经验法则是：带宽的增加速度至少是延迟改进速度的平方。

- 晶体管性能与连线的发展

	集成电路的制造工艺是用特征尺寸（feature size）来衡量的，所谓特征尺寸就是一个品体管或一条连线在x轴方向或y轴方向的最小尺寸。待征尺寸已经从1971年的10微米减小到2017年的0.016微米。事实上，单位已经变了，2011年的特征尺寸被称为“16纳米”（16nm）.7纳米的芯片正在研发之中。由于每平方毫米硅片上的晶体管数目是由单个晶体管的表面积决定的，所以当特征尺寸线性减小时，晶体管密度将呈二次方增长。
	不过，晶体管性能的提升更加复杂。当特征尺寸缩小时，器件在水平方向的缩小服从平方律，在垂直方向上也会缩小。在垂直方向上缩小时，需要降低工作电压，以保持晶体管的正常工作和可靠性。缩放因子的这种组合效果使晶体管性能和工艺特征尺寸之间产生了复杂的关系。大致来说，晶体管性能的提高与特征尺寸的减小呈线性关系。
	当特征尺寸减小时，晶体管性能线性提升，而晶体管数目却呈二次方增加，这既是挑战，也是机遇，计算机架构师正是解决此类问题的！在微处理器发展的早期，借助晶体管密度的这种快速增长，微处理器迅速从4位发展到8位、16位、32位乃至64位。最近几年，密度的增长已经足以支持在一个芯片上引入多个处理器，支持更宽的SIMD单元、推测执行和缓存中的许多创新，第2、3、4、5章将会讨论这些内容。
	尽管晶体管的性能通常会随着特征尺寸的减小而提升，但集成电路中的连线却不会如此。具体来说，一段连线的信号延迟与其电阻和电容的乘积成正比。当然，当特征尺寸减小时，连线会变短，但单位长度的电阻和电容都会变差。这种关系很复杂，这是因为电阻和电容都依赖于工艺的具体细节、连线的几何形状、连线的负载，甚至与其他结构的邻近程度。偶尔也会有工艺方面的改进，比如铜的引入，这些改进会一次性地缩短连线延迟。
	一般来说，与晶体管性能相比，连线延迟方面的改进小得可怜，这增大了设计人员面临的挑战。在过去几年里，除了功耗限制之外，连线延迟已经成为大型集成电路的主要设计障碍，而且往往比晶体管开关延迟还要关键。信号在连线上的传播延迟消耗了越来越多的时钟周期，而功耗对时钟周期的影响大于连线延迟。

==== 集成电路中的功耗和能耗趋势

今天，对于几乎所有类型的计算机来说，能耗都是计算机设计人员面对的最大挑战。第一，必须将电源引人芯片，并进行分配，而现代微处理器仅仅为供电和接地就使用了数百个管脚和多个互连层。第二，功耗以热的形式耗散，必须降低。

- 功耗与能耗：系统视角

	系统架构师或用户应当如何考虑性能、功耗和能耗呢?从系统架构师的角度来看，共有3个主要关注事项。

	第一，处理器需要的最大功耗是多少?
	满足功耗要求对于确保操作正确非常重要。例如。如果处理器的预期功耗大于电源系统能够提供的功耗(也就是试图汲取的电流大于电源系统能够提供的电流），通常会导致电压下降，而电压下降可能会导致器件无法正常工作。现代处理器在峰值电流时的功耗变化范围很大，因此提供了电压指数方法，让处理器能够减缓速度，在惠大幅度内调整电压。显然，这样会降低性能。
	
	第二，持续功耗是多少？
	这个指标通常称为热设计功耗（thermal design power,TDP)因为它是对系统散热提出的要求。TDP既不是峰值功耗（峰值功耗通常要高1.5倍），也不是在给定计算期间的（可能更低的）实际平均功耗。在为一个系统适配电源时，其功耗通常要大于TDP，而冷却系统的散热通常也不小于TDP。如果散热能力不足，处理器中的结点温度可能会超出最大值，导致器件故障，甚至水久损坏。由于最大功耗可能超出TDP指定的长期平均值（从而使热量和温度上升），所以现代处理器提供了两项功能来帮助管理热量——当温度接近结点温度上限时，电路降低时钟频率，从而减小功耗；如果这个动作不管用，则启用热过载保护装置强制芯片断电。
	
	第三,能耗和能效是多少？
	回想一下，功耗就是单位时间的能耗1瓦=1焦/秒。哪个指标更适合用来对比处理器：能耗还是功耗？一般来说，能耗更好一些，因为它与特定任务以及该项任务所需要的时间相关联。具体来说，执行一项工作负载的能耗等子平均功耗乘以此项工作负载的执行时间。

- 微处理器内部的能耗与功耗

	配电、散热和防热点的难度日益增加。能耗是现在使用晶体管的主要限制因素。因此，现代微处理器提供了许多技术，试图在时钟频率和电源电压保持不变的情况下，提高能效。
	
	（1）以逸待劳
	今天的大多数微处理器会关闭非活动模块的时钟，以降低能耗和动态功耗。例如，如果当前没有执行浮点指令，浮点单元的时钟将被禁用。如果一些核处于空闲状态，它们的时钟也会被停止。
	
	（2)动态电压一频率调整(dynamic voltage-frequency scaling,DVFS）
	第二种技术直接来自上述公式。PMD、笔记本计算机，甚至服务器都会有一些活跃程度较低的时期，在此期间不需要以最高时钟频率和电压运转。现代微处理器通常提供几种能够降低功耗和能耗的工作时钟频率和工作电压。图l-5绘制了当工作负载降低时，服务器通过DVFS可能节省的功耗，3种时钟频率为2.4GHz、1.8GHz和1GHz。在这两个步骤中的每一步，服务器可以节省大约10%-15%的总功耗。

	（3）针对典型情景的设计
	由于PMD和笔记本计算机经常空闲，所以内外存储器都提供了低功耗模式，以减少能耗，例如，DRAM具有一系列功耗逐渐降低的低功耗模式，用于延长PMD和笔记本计算机的电池寿命；同时，针对磁盘也提出了一些建议，即在空闲时使其采用低转速模式，以省电，遗憾的是，在这些模式下，你不能访问DRAM和磁盘，无论访问速度有多低，你都必须返回全速工作模式才能进行读写。前面曾经提到，PC微处理器的设计考虑了一种更典型的情景：在高工作温度下密集使用。这种设计依靠片上温度传感器检测应当在什么时候自动减少活动，以避免过热。这种“紧急减速”使制造商能够针对更典型的情景进行设计，如果所运行程序的耗电量远远超出典型情况，则可以依靠这种安全机制来保证安全。
	
	（4）超频
	Intel在2008年开始提供Turbo模式，在这种模式中，芯片可以判定在少数几个核上以较高时钟频率短时运行是安全的，直到温度开始上升为止。例如，3.3GHzCore i7可以在很短的时间内以3.6GHz的频率运行。

	尽管通常认为动态功耗是CMOS中功耗的主要来源，但由于即使晶体管处于关闭状态也存在泄漏电流，所以静态功耗也逐渐成为一个重要问题：
[stem]
++++
功耗_{静态} \propto 电流_{静态} \times 电压
++++
	也就是说，静态功耗与器件数目成正比。因此，如果增加晶体管的数目，即使它们处于空闲状态也会增加功耗，并且当品体管的尺寸较小时，处理器中的泄漏电流会增大。所以，功耗极低的系统甚至会关闭非活动模块的电源（电源门控，power gating），以控制由泄漏电流导致的损失

- 计算机体系结构因为能耗限制而发生变化

	随着晶体管发展速度的减缓，计算机架构师必须寻求其他提高能效的方法。事实上，在给定能耗预算的情况下，今天很容易设计出一种微处理器，其拥有的晶体管数多到不能同时全部开启。这种现象称为暗硅（dark silicon），这是因为在任意时刻，由于热限制，一个芯片的大部分都不能使用（“暗”）。这一观测结果使架构师们重新研究了处理器设计的基本原理，以寻求更高的能效。

==== 成本趋势

	成本趋势是推动计算机技术发展的另一大因素。随着技术的进步和生产规模的扩大，计算机系统的成本逐渐降低。时间、产量和大众化成本的降低使得高性能计算逐步进入更多消费者的日常生活。特别是在过去几十年中，摩尔定律的推动使得计算机硬件的价格不断下降，处理能力不断提升，这为个人计算机的普及奠定了基础。随着市场需求的扩大和技术成熟，计算机设备不仅在性能上得到了提高，成本方面也得到了显著优化，推动了计算机的民主化，使得各种计算设备更加普及。

	集成电路的成本随着生产工艺的进步而不断降低。随着半导体制造技术的不断发展，集成电路的生产成本逐渐下降。规模化生产、精密制造和先进工艺的引入使得每个晶体管的成本大幅降低，从而降低了整体集成电路的价格。这种成本降低不仅使得更为复杂的电路能够得到实现，还推动了消费电子产品的普及，例如智能手机、平板电脑等。

	制造成本与运营成本的变化也对计算机的发展起到了重要作用。随着新型制造工艺和自动化生产线的引入，集成电路的制造成本不断降低。然而，运营成本，尤其是在大规模数据中心和云计算环境中的能源消耗和维护费用，仍然是计算机技术发展中的一大挑战。为了降低运营成本，越来越多的企业开始采用高效能硬件、绿色数据中心和智能管理系统，这不仅能降低能源消耗，还能延长设备的使用寿命，最终为企业节省成本。

<<<