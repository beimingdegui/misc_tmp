= 计算机体系结构

李龙斌 - 202432466@mail.sdu.edu.cn

:stem: latexmath
:icons: font
:source-highlighter: coderay
:sectnums:
:sectlinks:
:sectnumlevels: 4
:toc: left
:toc-title: 目录
:toclevels: 3  r

== 计算机概论与设计分析基础

TIP: 为表格与图片标记序号并在正文中引用

=== 引言

=== 计算机的分类

1. 物联网/嵌入式计算机

	物联网/嵌入式计算机是一种专门为特定功能设计的计算机系统，通常嵌入到更大的设备或系统中，以实现专用的任务。这类计算机通常具备低功耗、小体积和高可靠性的特点。它们硬件资源有限，通常运行轻量级的实时操作系统或者无操作系统，专注于单一或少量功能的高效执行。嵌入式计算机广泛应用于智能家居设备（如智能音箱、恒温器）、工业控制系统（如PLC）、汽车电子（如自动驾驶辅助系统）、医疗设备（如便携式医疗监测设备）等场景中。树莓派、ESP32、Arduino等设备是这一领域的典型代表。

2. 个人移动设备

	个人移动设备是为便携性设计的小型计算设备，如智能手机、平板电脑和智能手表。它们集成了触控屏幕、摄像头、麦克风等多种输入输出设备，通常运行移动操作系统（如Android或iOS），支持多任务处理。个人移动设备的特点是设计轻薄便携，具有无线连接能力（如Wi-Fi、蜂窝网络）以及较长的电池续航时间。这类设备已经成为现代人生活的核心工具，广泛用于通信（如电话、视频通话）、娱乐（如游戏、音乐、视频）、工作（如电子邮件、文档处理）和导航等场景。智能手机是最常见的个人移动设备，平板电脑和智能手表则进一步扩展了其使用范围。

3. 桌面计算机

	桌面计算机是一种固定式个人计算机，通常由主机、显示器、键盘和鼠标组成，适合放置在工作台上。其特点是性能强大、散热能力优越，可扩展性强，硬件组件（如内存、存储、显卡等）可以根据需要进行更换和升级。桌面计算机主要用于高性能任务，如办公应用（文档处理、数据分析）、高性能游戏、内容创作（视频剪辑、图形设计）、编程开发等。相比于笔记本电脑，桌面计算机更适合需要长期使用或性能要求较高的场景。常见的品牌台式机如戴尔OptiPlex，DIY装机则提供了更大的灵活

4. 服务器

	服务器是一种专门为提供服务设计的高性能计算机，通常位于数据中心，为其他计算机或用户提供计算、存储和网络服务。服务器的特点是性能强劲、稳定可靠，支持多线程、多任务处理，并具备冗余设计（如双电源、ECC内存）以确保高可用性。它们通过专用的硬件和软件（如虚拟化技术）来实现远程管理和资源共享。服务器被广泛应用于托管网站（Web服务器）、运行数据库（数据库服务器）、支持网络通信（邮件服务器、DNS服务器）以及提供云计算服务等场景。典型的服务器设备包括刀片式服务器（如Dell PowerEdge）和机架式服务器（如HPE ProLiant）。

5. 分布式集群（计算机）

	分布式集群是一种由多台计算机通过网络连接组成的计算系统，这些计算机协同工作，共同完成复杂任务。它的特点是高可扩展性，可以通过增加计算节点提升系统性能，同时具备高容错性，部分节点故障不会影响整体运行。分布式集群通常采用资源共享的方式，将任务分配到各个节点进行并行处理。它广泛应用于高性能计算（如科学模拟、基因分析）、大数据处理（如Hadoop和Spark平台）、云服务（如AWS和Google Cloud）以及分布式存储（如Ceph和HDFS）。超级计算机（如Fugaku）和云计算集群（如Kubernetes）是分布式集群的重要代表。

=== 计算机的组成

==== 硬件组成部分

1. 输入设备

	输入设备是计算机硬件的重要组成部分，用于将外部信息转换为计算机能够识别和处理的电子信号。这些设备通常负责捕捉用户的指令或环境中的数据，以便计算机能够执行相应的操作。常见的输入设备包括键盘、鼠标、触摸屏、麦克风、摄像头以及传感器等。它们的主要特点是多样化和精确性，例如键盘适合精确输入文本和命令，而麦克风可以捕捉声音信号以供语音识别和通信使用。输入设备广泛应用于各类场景，从办公和游戏到自动化监控和虚拟现实体验，为计算机与用户之间的交互提供了多种可能性。

2. 输出设备

	输出设备是计算机将处理结果以用户可感知形式输出的硬件部分。它们的主要作用是将计算机内部的数字信息转换为可视、可听或其他形式的表现，以便用户理解和利用。常见的输出设备包括显示器、打印机、扬声器、耳机以及触觉反馈设备等。输出设备的特点在于提供高质量的表现形式，例如高分辨率显示器可以展现清晰的图像和视频，扬声器可以播放高保真的音频内容。这些设备在日常生活、专业工作和娱乐中应用广泛，例如在设计领域显示高分辨率的图像，在教育领域播放多媒体内容，以及在虚拟现实中提供多感官的沉浸式体验。

3. 储存器

	储存器是计算机用于保存数据和程序的硬件部件，分为不同层次以满足性能与容量需求的平衡。层次化存储的结构通常包括高速缓存（Cache）、主存（RAM）和外存（如硬盘、固态硬盘）。高速缓存存储常用数据，具有低延迟、高速度的特点；主存作为计算机的工作内存，支持快速读写；外存则负责长期保存大量数据。储存器的层次化设计通过不同级别的速度和容量优化了计算机系统的性能与成本。储存器的广泛应用包括在游戏中提供快速加载、在数据中心存储海量信息，以及在嵌入式设备中保存操作程序和运行时数据。

4. 运算器

	运算器是计算机执行算术和逻辑运算的核心部件，通常由加法器、逻辑单元和寄存器等组成。其主要功能是处理指令中的计算任务，包括整数运算、浮点运算和逻辑判断等。运算器的特点在于速度和精确性，它能够在短时间内完成复杂的数学运算，并为其他硬件提供支持。现代运算器通常集成在处理器中，通过并行计算技术进一步提升性能。运算器广泛应用于科学计算、图形渲染、加密解密以及人工智能模型训练等领域，是计算机完成复杂任务的基础硬件。

5. 控制器

	控制器是计算机的指挥中心，用于解析并执行指令，协调其他硬件部件的工作。控制器通过时钟信号驱动整个系统，并负责管理指令的获取、解码和执行过程。现代控制器与运算器一起构成了处理器（CPU），具备更高的集成度和性能。控制器支持多种并行技术，包括指令级并行（同时执行多条指令）、数据级并行（对大规模数据并行操作）以及线程级并行（同时运行多个任务）。这些特点使控制器能够处理多样化和复杂的任务。控制器的应用涵盖了从日常计算到高性能计算领域，如图像处理、多线程编程以及虚拟化平台支持，是现代计算系统的核心。

==== 软件组成部分

1. 应用软件

	应用软件是专门为用户完成特定任务而开发的软件，直接服务于用户的需求。它的定义涵盖了从单一功能工具到综合型解决方案的广泛范围，例如文字处理软件、图形设计工具、会计软件、社交媒体应用等。应用软件的特点是面向用户需求设计，界面友好，功能明确，并能够在各种设备和平台上运行，如桌面计算机、移动设备和云平台。应用软件在日常生活和工作中应用广泛，例如在办公场景中使用Microsoft Office进行文档处理，在娱乐领域通过媒体播放器观看电影，在专业领域利用AutoCAD进行工程设计，以及在电子商务平台上进行购物和交易。应用软件的种类和功能随着用户需求的变化而不断丰富。

2. 系统软件

	系统软件是计算机运行的基础，主要负责管理硬件资源并为应用软件提供支持和运行环境。它包括操作系统（如Windows、Linux、macOS）、驱动程序、系统工具和基础库等。系统软件的特点是抽象复杂硬件操作，提供标准化接口，确保硬件资源的高效分配和安全管理。它通常以后台运行的方式为用户和应用软件提供服务。操作系统是系统软件的核心部分，负责内存管理、文件系统、进程调度和设备管理等功能。此外，系统软件的可靠性和性能对整个计算机系统的稳定性至关重要。它广泛应用于个人电脑、服务器、移动设备以及嵌入式系统中，为用户的高效使用提供保障，同时也为应用软件开发者提供了统一的平台。

=== 计算机体系结构

计算机体系结构包含计算机的物理实现及其逻辑设计（硬件）、各个部件之间的互连（组成，也称为微体系结构）。

==== 七个伟大思想

[options="header"]
|=======================
|思想 |概括
|使用抽象简化设计|通过隐藏底层细节，专注于高层设计逻辑，从而简化复杂系统的开发。这一思想类似于函数的使用：函数封装了具体的实现逻辑，对外提供统一的接口，使得开发者可以专注于高层结构设计，而无需了解底层实现细节。应用场景包括模块化编程、操作系统的虚拟内存管理以及软件工程中的面向对象设计。
|加速经常性事件|针对系统中常见的操作进行优化，使其运行得更快、更高效。这一思想基于“常见情形出现得更频繁”这一观察，例如处理器优化分支预测的命中路径或缓存对热点数据的快速访问。这种方法使得系统能将资源优先分配给高频事件，从而整体提升性能。
|通过并行提高性能|通过指令级并行（如流水线技术）、数据级并行（如向量体系结构和GPU）、线程级并行（如多核处理器）来提高系统性能。并行化是现代计算机设计中的核心理念之一，其目的是充分利用硬件资源，在多个层次上同时处理数据和指令。例如，GPU擅长数据级并行，在图形处理和深度学习中具有极高效率。
|通过流水线提高性能|流水线技术是一种指令级并行实现方式，它将指令分解为多个阶段，各阶段可以同时处理不同的指令部分，从而提高吞吐量。这种方法类似于工业生产线，将复杂任务分解为多个子任务，各个子任务可以并行执行。应用于处理器设计中，流水线技术显著提升了指令执行的效率。
|通过预测提高性能|分支预测是一种提高性能的技术，通过提前执行可能的分支路径来减少因条件分支而造成的停顿。当预测结果正确时，性能显著提升；如果预测错误，系统则会撤回无效的操作。这一技术广泛用于现代处理器中，以减少分支指令对流水线的干扰。
|储存层次|存储层次结构是通过缓存机制和虚拟存储来优化数据访问速度的一种设计思想。系统将经常使用的数据存储在较快的存储层（如缓存）中，而将较少访问的数据存储在容量较大的层（如磁盘）中。这种机制通过权衡存取速度和存储容量，提升了整体性能。
|通过冗余提高可靠性|冗余设计在系统中增加了额外的组件或信息，用于在发生故障时代替失效部分，从而保持系统的正常运行。例如，RAID存储技术通过冗余磁盘阵列来保护数据安全，冗余电源设计确保即使单个电源失效，系统仍能正常运行。这种方法提升了系统的容错性和可靠性。
|=======================

=== 计算机的性能

计算机处于不同场景下对于性能的关注点不一样，如个人用户更关注计算机的响应时间，而服务器更关心它的吞吐量与带宽。对于性能好坏的评价在不同场景下需要使用不同的标准。

==== 性能的定义与度量

时间是计算机性能的衡量标准

[options="header"]
|=======================
|时间的定义|内容
|响应时间|响应时间指的是完成某项任务所需的总时间，包括所有相关开销。这不仅仅是CPU执行任务的时间，还包含等待I/O操作的时间、内存访问时间以及操作系统调度时间等。响应时间通常用于衡量系统的整体性能，特别是在实时系统或交互式应用中。例如，当用户点击一个网页链接，响应时间指从点击开始到页面完全加载并呈现的总时间。优化响应时间可以提升用户体验，其关键策略包括优化I/O性能、减少系统开销以及提升任务调度的效率。
|CPU执行时间|CPU执行时间是指程序在CPU上实际执行指令所花费的时间，通常细分为用户CPU时间和系统CPU时间。用户CPU时间是程序运行其自身代码所用的时间，而系统CPU时间则是操作系统为该程序提供服务所用的时间（如处理系统调用）。CPU执行时间通常被用来评估程序的计算效率，与响应时间不同，它忽略了外部因素的干扰（如I/O等待）。程序员可以通过优化算法、减少上下文切换以及充分利用硬件资源（如向量化和多线程）来减少CPU执行时间。
|时钟周期数|时钟周期数是衡量计算机硬件完成基本功能速度的指标，它表示某项操作所需的时钟周期总数。每个时钟周期由处理器的时钟频率定义，例如一个1 GHz的处理器的时钟周期为1纳秒。时钟周期数反映了指令执行的效率，是评估硬件性能的重要指标。通过减少每条指令所需的时钟周期数（CPI，Cycles Per Instruction）或提高处理器的时钟频率，可以提升计算性能。此外，现代处理器通过流水线和并行计算技术进一步优化时钟周期的利用率。
|=======================

==== CPU性能及其度量因素

[stem]
++++
程序的CPU执行时间 = 程序的CPU时钟数 \times 时钟周期时间
++++

由于时钟频率和时钟周期长度互为倒数，故另一种表达形式为：

[stem]
++++
程序的CPU执行时间 = \frac{程序的CPU时钟数}{时钟频率}
++++

这个公式表明，硬件设计者减少程序执行所需的CPU时钟周期数或缩短时钟周期长度。就能改进性能。

==== 指令性能

[stem]
++++
CPU时钟周期数 = 程序的指令数 \times 指令平均时钟周期数（CPI）
++++

CPI（Cycles Per Instruction）是指处理器平均执行一条指令所需的时钟周期数。它是衡量计算机处理器性能的重要指标之一，用于描述指令执行效率。公式如下：

[stem]
++++
CPI = \frac{总时钟周期数}{指令总数}
++++

CPI的大小反映了处理器执行指令的效率。较低的CPI表示处理器能够在更少的时钟周期内完成指令执行，而较高的CPI则意味着指令执行效率较低。CPI受多种因素影响，包括指令集架构、处理器的设计（如流水线深度、并行执行能力）以及指令的性质（简单指令和复杂指令的CPI可能差异较大）。CPI提供了一种相同指令系统在不同实现下比较性能的方法，因为在指令系统不变的情况下，一个程序执行的指令数是不变的。

==== 经典CPU性能公式

[stem]
++++
CPU时间 = 指令数 \times 指令平均时钟周期数（CPI）\times 时钟周期时间
++++

或：

[stem]
++++
CPU时间 = \frac{指令数 \times 指令平均时钟周期数（CPI）}{时钟周期时间}
++++

==== 性能的测量、报告和汇总

|===
.2+|基准测试 |桌面基准测试|处理器密集型测试、图形密集型测试
|服务器基准测试|事务处理基准测试
|性能测试结果 2+a|
[stem]
++++
SPECRatio = \frac{基准计算机上的执行时间}{待评估计算机上的执行时间}
++++
|===

- 处理器密集型测试

	主要关注处理器在执行大量计算任务时的效率。这种测试通常以数学运算、科学计算或加密算法为核心，测量处理器执行这些高计算强度任务的速度。它能够反映处理器的算术运算能力、指令执行效率以及寄存器操作的性能。处理器密集型测试广泛应用于高性能计算领域、科学研究以及对处理器进行性能对比分析。例如，使用基准工具如SPEC CPU基准套件来测试处理器在处理密集型任务时的表现，从而为用户或开发者选择硬件提供数据支持。

- 图形密集型测试

	主要用于评估系统在处理复杂图形任务时的能力，特别是显卡（GPU）的性能。这种测试通常通过渲染复杂的三维场景、光影效果和纹理操作，测量系统的帧率（FPS）、延迟和抗锯齿效果等指标。图形密集型测试反映了系统在游戏、视频渲染以及虚拟现实等场景中的性能表现。这类测试通常采用专业工具，例如3DMark、Unigine Heaven等，以模拟高负载图形任务的场景，从而判断显卡与驱动程序的综合性能。图形密集型测试对于游戏开发者、图形设计师和硬件厂商具有重要意义，能够帮助他们优化软件与硬件的兼容性和性能。

- 事务处理基准测试

	事务处理通常涉及大量的数据库操作，如插入、更新、查询以及删除数据，同时要求系统具备较高的并发处理能力和数据一致性。事务处理基准测试通常使用标准化的工作负载模型，如TPC-C（在线事务处理基准）或TPC-H（决策支持系统基准），来测量系统在多用户环境下的吞吐量、响应时间和扩展能力。这类测试广泛应用于企业信息管理、电子商务和金融服务领域，用以评估数据库管理系统、服务器和存储设备的性能，并为系统优化和扩展提供数据支持。

=== 计算机的发展方向

1. 技术上，由于摩尔定律的失效，缩小晶体管的尺寸与增加晶体管的数量越来越困难，需要从新材料新架构中寻求突破。另外，由于网络速度的加快，远程计算机、云服务将越来越实用与流行。

2. 能耗上，在移动设备与嵌入式设备（物联网）中，在低功耗的情况下实现高性能仍然是突破点

3. 芯片制造中，随着制程工艺的减少，芯片生产难度加大。改良制造工艺提高良率能有效降低成本

==== 技术趋势

TIP: 图

- 性能趋势：带宽胜过延迟

	带宽和吞吐量是指在给定时间内完成的总工作量，比如在进行磁盘读写时每秒传输的兆字节数。与之相对，延迟或响应时间是指一个事件从开始到完成所经过的时间，比如一次磁盘访问需要的毫秒数。在目前技术的发展过程中，带宽的改进速度超过延迟，而且这一趋势很可能持续下去。一个简单的经验法则是：带宽的增加速度至少是延迟改进速度的平方。

- 晶体管性能与连线的发展

	集成电路的制造工艺是用特征尺寸（feature size）来衡量的，所谓特征尺寸就是一个品体管或一条连线在x轴方向或y轴方向的最小尺寸。待征尺寸已经从1971年的10微米减小到2017年的0.016微米。事实上，单位已经变了，2011年的特征尺寸被称为“16纳米”（16nm）.7纳米的芯片正在研发之中。由于每平方毫米硅片上的晶体管数目是由单个晶体管的表面积决定的，所以当特征尺寸线性减小时，晶体管密度将呈二次方增长。
	不过，晶体管性能的提升更加复杂。当特征尺寸缩小时，器件在水平方向的缩小服从平方律，在垂直方向上也会缩小。在垂直方向上缩小时，需要降低工作电压，以保持晶体管的正常工作和可靠性。缩放因子的这种组合效果使晶体管性能和工艺特征尺寸之间产生了复杂的关系。大致来说，晶体管性能的提高与特征尺寸的减小呈线性关系。
	当特征尺寸减小时，晶体管性能线性提升，而晶体管数目却呈二次方增加，这既是挑战，也是机遇，计算机架构师正是解决此类问题的！在微处理器发展的早期，借助晶体管密度的这种快速增长，微处理器迅速从4位发展到8位、16位、32位乃至64位。最近几年，密度的增长已经足以支持在一个芯片上引入多个处理器，支持更宽的SIMD单元、推测执行和缓存中的许多创新，第2、3、4、5章将会讨论这些内容。
	尽管晶体管的性能通常会随着特征尺寸的减小而提升，但集成电路中的连线却不会如此。具体来说，一段连线的信号延迟与其电阻和电容的乘积成正比。当然，当特征尺寸减小时，连线会变短，但单位长度的电阻和电容都会变差。这种关系很复杂，这是因为电阻和电容都依赖于工艺的具体细节、连线的几何形状、连线的负载，甚至与其他结构的邻近程度。偶尔也会有工艺方面的改进，比如铜的引入，这些改进会一次性地缩短连线延迟。
	一般来说，与晶体管性能相比，连线延迟方面的改进小得可怜，这增大了设计人员面临的挑战。在过去几年里，除了功耗限制之外，连线延迟已经成为大型集成电路的主要设计障碍，而且往往比晶体管开关延迟还要关键。信号在连线上的传播延迟消耗了越来越多的时钟周期，而功耗对时钟周期的影响大于连线延迟。

==== 集成电路中的功耗和能耗趋势

今天，对于几乎所有类型的计算机来说，能耗都是计算机设计人员面对的最大挑战。第一，必须将电源引人芯片，并进行分配，而现代微处理器仅仅为供电和接地就使用了数百个管脚和多个互连层。第二，功耗以热的形式耗散，必须降低。

- 功耗与能耗：系统视角

	系统架构师或用户应当如何考虑性能、功耗和能耗呢?从系统架构师的角度来看，共有3个主要关注事项。

	第一，处理器需要的最大功耗是多少?
	满足功耗要求对于确保操作正确非常重要。例如。如果处理器的预期功耗大于电源系统能够提供的功耗(也就是试图汲取的电流大于电源系统能够提供的电流），通常会导致电压下降，而电压下降可能会导致器件无法正常工作。现代处理器在峰值电流时的功耗变化范围很大，因此提供了电压指数方法，让处理器能够减缓速度，在惠大幅度内调整电压。显然，这样会降低性能。
	
	第二，持续功耗是多少？
	这个指标通常称为热设计功耗（thermal design power,TDP)因为它是对系统散热提出的要求。TDP既不是峰值功耗（峰值功耗通常要高1.5倍），也不是在给定计算期间的（可能更低的）实际平均功耗。在为一个系统适配电源时，其功耗通常要大于TDP，而冷却系统的散热通常也不小于TDP。如果散热能力不足，处理器中的结点温度可能会超出最大值，导致器件故障，甚至水久损坏。由于最大功耗可能超出TDP指定的长期平均值（从而使热量和温度上升），所以现代处理器提供了两项功能来帮助管理热量——当温度接近结点温度上限时，电路降低时钟频率，从而减小功耗；如果这个动作不管用，则启用热过载保护装置强制芯片断电。
	
	第三,能耗和能效是多少？
	回想一下，功耗就是单位时间的能耗1瓦=1焦/秒。哪个指标更适合用来对比处理器：能耗还是功耗？一般来说，能耗更好一些，因为它与特定任务以及该项任务所需要的时间相关联。具体来说，执行一项工作负载的能耗等子平均功耗乘以此项工作负载的执行时间。

- 微处理器内部的能耗与功耗

	配电、散热和防热点的难度日益增加。能耗是现在使用晶体管的主要限制因素。因此，现代微处理器提供了许多技术，试图在时钟频率和电源电压保持不变的情况下，提高能效。
	
	（1）以逸待劳
	今天的大多数微处理器会关闭非活动模块的时钟，以降低能耗和动态功耗。例如，如果当前没有执行浮点指令，浮点单元的时钟将被禁用。如果一些核处于空闲状态，它们的时钟也会被停止。
	
	（2)动态电压一频率调整(dynamic voltage-frequency scaling,DVFS）
	第二种技术直接来自上述公式。PMD、笔记本计算机，甚至服务器都会有一些活跃程度较低的时期，在此期间不需要以最高时钟频率和电压运转。现代微处理器通常提供几种能够降低功耗和能耗的工作时钟频率和工作电压。图l-5绘制了当工作负载降低时，服务器通过DVFS可能节省的功耗，3种时钟频率为2.4GHz、1.8GHz和1GHz。在这两个步骤中的每一步，服务器可以节省大约10%-15%的总功耗。

	（3）针对典型情景的设计
	由于PMD和笔记本计算机经常空闲，所以内外存储器都提供了低功耗模式，以减少能耗，例如，DRAM具有一系列功耗逐渐降低的低功耗模式，用于延长PMD和笔记本计算机的电池寿命；同时，针对磁盘也提出了一些建议，即在空闲时使其采用低转速模式，以省电，遗憾的是，在这些模式下，你不能访问DRAM和磁盘，无论访问速度有多低，你都必须返回全速工作模式才能进行读写。前面曾经提到，PC微处理器的设计考虑了一种更典型的情景：在高工作温度下密集使用。这种设计依靠片上温度传感器检测应当在什么时候自动减少活动，以避免过热。这种“紧急减速”使制造商能够针对更典型的情景进行设计，如果所运行程序的耗电量远远超出典型情况，则可以依靠这种安全机制来保证安全。
	
	（4）超频
	Intel在2008年开始提供Turbo模式，在这种模式中，芯片可以判定在少数几个核上以较高时钟频率短时运行是安全的，直到温度开始上升为止。例如，3.3GHzCore i7可以在很短的时间内以3.6GHz的频率运行。

	尽管通常认为动态功耗是CMOS中功耗的主要来源，但由于即使晶体管处于关闭状态也存在泄漏电流，所以静态功耗也逐渐成为一个重要问题：
[stem]
++++
功耗_{静态} \propto 电流_{静态} \times 电压
++++
	也就是说，静态功耗与器件数目成正比。因此，如果增加晶体管的数目，即使它们处于空闲状态也会增加功耗，并且当品体管的尺寸较小时，处理器中的泄漏电流会增大。所以，功耗极低的系统甚至会关闭非活动模块的电源（电源门控，power gating），以控制由泄漏电流导致的损失

- 计算机体系结构因为能耗限制而发生变化

	随着晶体管发展速度的减缓，计算机架构师必须寻求其他提高能效的方法。事实上，在给定能耗预算的情况下，今天很容易设计出一种微处理器，其拥有的晶体管数多到不能同时全部开启。这种现象称为暗硅（dark silicon），这是因为在任意时刻，由于热限制，一个芯片的大部分都不能使用（“暗”）。这一观测结果使架构师们重新研究了处理器设计的基本原理，以寻求更高的能效。

==== 成本趋势

	成本趋势是推动计算机技术发展的另一大因素。随着技术的进步和生产规模的扩大，计算机系统的成本逐渐降低。时间、产量和大众化成本的降低使得高性能计算逐步进入更多消费者的日常生活。特别是在过去几十年中，摩尔定律的推动使得计算机硬件的价格不断下降，处理能力不断提升，这为个人计算机的普及奠定了基础。随着市场需求的扩大和技术成熟，计算机设备不仅在性能上得到了提高，成本方面也得到了显著优化，推动了计算机的民主化，使得各种计算设备更加普及。

	集成电路的成本随着生产工艺的进步而不断降低。随着半导体制造技术的不断发展，集成电路的生产成本逐渐下降。规模化生产、精密制造和先进工艺的引入使得每个晶体管的成本大幅降低，从而降低了整体集成电路的价格。这种成本降低不仅使得更为复杂的电路能够得到实现，还推动了消费电子产品的普及，例如智能手机、平板电脑等。

	制造成本与运营成本的变化也对计算机的发展起到了重要作用。随着新型制造工艺和自动化生产线的引入，集成电路的制造成本不断降低。然而，运营成本，尤其是在大规模数据中心和云计算环境中的能源消耗和维护费用，仍然是计算机技术发展中的一大挑战。为了降低运营成本，越来越多的企业开始采用高效能硬件、绿色数据中心和智能管理系统，这不仅能降低能源消耗，还能延长设备的使用寿命，最终为企业节省成本。

== 指令系统

=== 汇编语言及其操作数

汇编语言是一种介于机器语言和高级语言之间的低级编程语言，它以符号化的助记符代替机器语言中的二进制操作码和内存地址，帮助程序员更容易地与硬件交互。汇编语言的作用主要体现在直接控制硬件、优化程序性能和深入理解计算机系统等方面。在操作系统开发、驱动程序编写和嵌入式系统设计中，汇编语言因其对硬件资源的精确控制而被广泛应用。此外，汇编语言还常用于程序性能优化，通过手动调整指令和资源分配，可以实现更高效的代码执行。

汇编语言具有与硬件高度相关、符号化表示低级操作、高效率但复杂性高等特点。由于其紧密依赖于特定的处理器架构，每种汇编语言的指令集和功能都与相应的硬件设计息息相关，导致它在不同平台之间无法直接移植。相比于高级语言，汇编语言的可读性和可维护性较差，但在运行效率上更具优势。其符号化的表示方式虽然简化了机器语言的复杂性，但仍需要程序员对底层硬件有深入的理解和掌控。

汇编语言与高级语言处于不同的抽象层次，两者既有显著区别又具有密切联系。高级语言通过抽象屏蔽底层硬件细节，使程序设计更接近自然语言，极大地提高了开发效率和可移植性。然而，高级语言编写的程序需要经过编译器翻译成汇编代码，最终再由汇编器转为机器码，这使得高级语言程序的执行效率通常不如汇编语言。在实际开发中，高级语言和汇编语言往往结合使用。当程序对性能和硬件操作有极高要求时，开发者可以选择用汇编语言编写关键模块，将其嵌入到高级语言中，以兼顾系统性能与开发效率。汇编语言在优化代码性能和深入理解系统底层运作方面仍具有不可替代的价值，与高级语言共同构成了完整的编程工具体系。

汇编语言的操作数种类多样，通常包括立即数、寄存器和内存地址三种形式。立即数是直接嵌入指令中的具体值，表示常量数据，使用时无需额外的存储访问，因此处理速度快但灵活性较低。寄存器操作数指存储在处理器内部寄存器中的数据，由于寄存器是处理器中访问速度最快的存储单元，寄存器操作数的使用能够显著提高运算效率。然而，由于寄存器数量有限，寄存器操作数的应用通常需要精心规划和优化。内存地址操作数则指向存储在主存中的数据，虽然存储空间更大，但访问内存操作数需要额外的存储访问时间，可能影响指令执行的速度。

汇编语言的操作数具有低级性和直接性的特点，完全依赖于底层硬件的体系结构。每种处理器架构定义了支持的操作数类型、数量以及操作数的位置规则。例如，一些架构允许指令同时包含多个操作数，而另一些架构则限制为单一操作数或特定的寻址模式。这种对硬件特性的依赖使得汇编语言的操作数灵活性受到一定限制，同时导致其代码在不同硬件平台之间的可移植性较差。

操作数的寻址方式是汇编语言的另一个显著特点。处理器支持多种寻址模式，用于确定操作数的具体位置，包括直接寻址、间接寻址、寄存器寻址、偏移寻址等。不同的寻址方式为程序提供了多样化的操作数访问手段，使开发者可以根据具体需求优化代码性能和存储使用。例如，在循环操作中，偏移寻址可以简化数组元素的访问，而寄存器寻址则能最大限度地提高运算效率。

==== 存储器操作数

处理器只能在寄存器中保存少量数据，但是计算机内存可以存储数十亿数据元素。因此数据结构（数组和结构体）可以保存在内存中。由于RISC-V指令中的算术运算只作用于寄存器，因此，RISC-V必须包含在内存和寄存器之间传输数据的指令。这些指令称为数据传输指令。要访问内存中的字，指令必须提供内存地址。内存只是一个大型一维数组，其地址作为该数组的下标，从0开始。将数据从内存复制到寄存器的数据传输指令通常称为载入指令（load）。载入指令的格式是操作名称后面紧跟数据待取的寄存器，然后是寄存器和用于访问内存的常量。指令的常量部分和第二个寄存器中的内容相加组成内存地址。实际的RISC-V指令名称是lw，表示取字。

加载字和存储字是在RISC-V体系结构中存储器和寄存器之间传输字的指令。许多程序有着比计算机中寄存器数量更多的变量。所以，编译器会尽量把最常用的变量存放在寄存器中，剩下的存放在内存中，使用load和store在寄存器和内存之间传输变量。将不常用的变量（或稍后才使用的变量）存放到内存的过程称为寄存器换出。关于大小和速度的硬件设计原则表明内存一定比寄存器慢，因为寄存器更少。事实确实如此，如果数据在寄存器而不是内存中，数据访问速度会更快。而且，数据在寄存器中更有用。RISC-V算术指令可以读取两个寄存器，对它们进行操作并写入结果。RISC-V数据传输指令只读取一个操作数或写入一个操作数，并不对其进行操作。因此，与内存相比，寄存器的访问时间更短，吞吐率更高。这使得寄存器中的数据访问速度更快，使用更简单。与访问内存相比，访问寄存器所需的能耗也少得多。要获得最高的性能并节约能耗，指令系统体系结构必须有足够多的寄存器，并且编译器必须有效使用寄存器。

==== 常数或立即数操作数

通过把常数作为算术指令操作数，和从存储器中取出常数相比，操作速度更快，能耗更低。

常数0有另一个作用，通过有效使用它可以简化指令系统体系结构。例如可以使用常数0寄存器求原数的相反数。因此，RISC-V专用寄存器x0硬连线到常数0.根据使用频率来确定要定义的常数，这是第一章中重要思想加速经常性事件的实例。

==== 有符号数与无符号数

在计算机内部，有符号数（正负数）和无符号数的表示依赖于二进制编码方式。计算机使用固定长度的二进制位来表示数据，如何区分正数、负数或单纯的无符号数取决于所选的编码规则。

有符号数需要区分正数和负数，因此通常使用最高位（即最左侧的位）作为符号位，剩余的位表示数值。符号位为0表示正数，为1表示负数。以下是常用的有符号数表示方法：

- 原码

	原码是一种直接的表示方式，符号位加上数值的绝对值。例如，8位二进制中，+5表示为00000101，-5表示为10000101。虽然原码表示简单，但在进行运算时，符号位需要单独处理，运算逻辑较为复杂，因此不常用于计算机实际运算。

- 反码

	反码的符号位与原码相同，但负数的数值部分通过对原码取反（0变1，1变0）得到。例如，+5的反码是00000101，而-5的反码是11111010。反码在加减运算中简化了一部分逻辑，但依然存在问题，如表示零时会有+0和-0两种形式。

- 补码

	补码是计算机中最常用的有符号数表示方法。正数的补码与其原码相同，而负数的补码通过对原码取反后加1得到。例如，+5的补码为00000101，而-5的补码为11111011。补码的优点是可以将减法统一为加法运算，且解决了零的双重表示问题（补码中只有一种形式的零）。由于这些特性，补码成为现代计算机处理有符号数的标准。

无符号数的表示

无符号数只表示非负整数，因此所有二进制位都用于表示数值，不包含符号位。例如，在8位二进制中，00000000表示0，11111111表示255。无符号数的范围为stem:[(0, 2^n - 1)],其中stem:[n]是二进制位数。

=== 计算机中的指令表示

TIP: 图

RISC-V 的指令根据功能不同分为多种格式，例如 R 型、I 型、S 型、B 型、U 型和 J 型。这些格式共享某些字段，但也有独特部分。32 位指令的通用结构包括以下字段：

Opcode（操作码，7 位）

	位置：第 0-6 位（从右向左编号，最右侧为第 0 位）。
	含义：指定指令的基本操作类型，如算术运算、内存访问、控制流指令等。
	作用：操作码决定指令的功能类别，结合其他字段进一步解析具体操作。


rd（目标寄存器，5 位）

	位置：第 7-11 位。
	含义：指定操作结果的目标寄存器编号（0-31，对应 32 个寄存器）。
	作用：表示操作结果将存储到的寄存器。

funct3（功能码，3 位）

	位置：第 12-14 位。
	含义：提供次级操作分类，与操作码配合，用于进一步区分指令功能，例如加法与减法。
	作用：在同一操作码下区分具体操作类型。

rs1（源寄存器 1，5 位）

	位置：第 15-19 位。
	含义：指定第一个源操作数的寄存器编号。
	作用：表示操作中需要读取的第一个操作数。

rs2（源寄存器 2，5 位）

	位置：第 20-24 位。
	含义：指定第二个源操作数的寄存器编号。
	作用：表示操作中需要读取的第二个操作数（仅适用于部分指令类型，如 R 型指令）。

funct7（功能码扩展，7 位）

	位置：第 25-31 位。
	含义：提供进一步的操作区分信息，与 funct3 和操作码结合，确定特定指令行为（如区分加法和减法）。
	作用：用于增强功能分类，扩展指令集。

立即数字段（不同格式中的位置和长度可变）

	含义：表示常量值，用于偏移量、地址或立即操作数等用途。
	作用：立即数在不同指令格式中位置不同，但均用于表示直接参与操作的固定值。

TIP: 可以接着补充不同类型指令的格式

=== 逻辑操作指令

[cols="1,1,1,1", options="header"]
|===
| 逻辑操作类型 | C操作符 |Java操作符 | 对应的RISC-V指令

| 左移 (Shift Left)
| <<
|<<
| SLL 指令：`sll rd, rs1, rs2` 或 `slli rd, rs1, imm`

| 逻辑右移 (Shift Right Logical)
| >>
| >>>
| SRL 指令：`srl rd, rs1, rs2` 或 `srli rd, rs1, imm`

| 算术右移 (Shift Right Arithmetic)
| >>
| >>
| SRA 指令：`sra rd, rs1, rs2` 或 `srai rd, rs1, imm`

| 按位与 (Bitwise AND)
| &
| &
| AND 指令：`and rd, rs1, rs2`

| 按位或 (Bitwise OR)
| \|
| \|
| OR 指令：`or rd, rs1, rs2`

| 按位异或 (Bitwise XOR)
| ^
| ^
| XOR 指令：`xor rd, rs1, rs2`

| 按位非 (Bitwise NOT)
| ~
| ~
| 取反指令：`xori rd, rs1, -1`


|===

=== 决策指令

使用条件分支指令（beq、bne等）进行回跳（循环）或前跳（if）。

[cols="1,1,1", options="header"]
|===
| 指令 | 含义 | 功能描述

| `beq rs1, rs2, offset`
| Branch if Equal
| 如果`rs1`等于`rs2`，跳转到`PC + offset`指定的地址

| `bne rs1, rs2, offset`
| Branch if Not Equal
| 如果`rs1`不等于`rs2`，跳转到`PC + offset`指定的地址

| `blt rs1, rs2, offset`
| Branch if Less Than (Signed)
| 如果`rs1`小于`rs2`（有符号比较），跳转到`PC + offset`指定的地址

| `bge rs1, rs2, offset`
| Branch if Greater Than or Equal (Signed)
| 如果`rs1`大于或等于`rs2`（有符号比较），跳转到`PC + offset`指定的地址

| `bltu rs1, rs2, offset`
| Branch if Less Than (Unsigned)
| 如果`rs1`小于`rs2`（无符号比较），跳转到`PC + offset`指定的地址

| `bgeu rs1, rs2, offset`
| Branch if Greater Than or Equal (Unsigned)
| 如果`rs1`大于或等于`rs2`（无符号比较），跳转到`PC + offset`指定的地址

| `jal rd, offset`
| Jump and Link
| 跳转到`PC + offset`指定的地址，并将返回地址（`PC + 4`）保存到寄存器`rd`

| `jalr rd, rs1, offset`
| Jump and Link Register
| 跳转到寄存器`rs1 + offset`的地址，并将返回地址（`PC + 4`）保存到寄存器`rd`
|===

虽然常量通常很短并且适合12位字段，但有时它们也会更大。

RISC-V指令系统包括指令load upper immediate(取立即数高位，lui)，用于将20位常数加载到寄存器的第31位到第12位。最右边的12位全部用0填充。例如，这条指令允许使用两条指令创建32位常量。lui使用新的指令格式——U型，因为其他格式不能支持如此大的常量。

TIP: 补充例子p82

==== RISC-V寻址模式总结

[cols="1,1,1", options="header"]
|===
| 寻址模式 | 定义 | 应用与特点

| 立即数寻址
| 操作数直接嵌入指令中，作为常量值。
| 常用于加法、减法等运算，或加载、存储指令中的常量。
  示例：`addi rd, rs1, imm`，将`rs1`与立即数`imm`相加，并存储到`rd`寄存器。

| 寄存器寻址
| 操作数位于寄存器中，指令通过寄存器指定操作数的位置。
| 常用于寄存器之间的数据传输与算术运算。非常快速。
  示例：`add rd, rs1, rs2`，将`rs1`与`rs2`相加并将结果存储在`rd`中。

| 基址寻址
| 操作数地址通过基地址寄存器和立即数偏移量计算得出。
| 常用于内存访问，基址寄存器用于存储数据结构起始地址，偏移量指定数据位置。
  示例：`lw rd, offset(rs1)`，将内存地址`rs1 + offset`处的数据加载到`rd`。

| PC相对寻址
| 操作数的地址是相对于当前PC值的偏移量计算得出。
| 用于条件跳转与程序控制，确保程序在不同内存位置加载时的正确性。
  示例：`beq rs1, rs2, offset`，若`rs1`和`rs2`相等，跳转到`PC + offset`。
  示例：`jal rd, offset`，跳转到`PC + offset`并保存返回地址到`rd`寄存器。
|===

TIP: 附图p85

==== 条件分支指令

[source,]
----
// 如果rs1中的值与rs2中的值相等，那么PC跳转到标签L1处
beq rs1, rs2, L1

// 如果rs1中的值与rs2中的值不相等，那么PC跳转到标签了L2处
bne rs1, rs2, L2
----

==== 循环

[source,]
----
// rs1持续加一，直到rs1等于10则退出循环
addi rs1, rs0, 1
addi rs2, rsr0, 10
Loop:
addi rs1, rs1 ,1
beq rs1, rs2, Exit
j Loop
Exit:
//退出循环
----

TIP: 更改为公式块

对相等或不相等的判断可能是最常见的判断，但也有很多其他两个数之间的关系。例如，for循环可能需要判断下标变量是否小于0。完整的相互关系有小于（<）、小于等于（≤）、大于（>）、大于等于（≥）、相等（=）、不等于（≠）。

位模式的比较还必须处理有符号和无符号数之间的差别。有时候，最高有效位是1代表一个负数，当然，它小于任何正数（最高有效位是0）。另一方面，对于无符号整数，最高有效位是1表示大于任何最高有效位是0的数。（我们很快将利用最高有效位的这种双重含义来降低数组边界检查的成本。）RISC-V提供了指令来处理这两种情况。这些指令与beq和bne具有相同的形式，但是执行不同的比较。小于则分支指令（b1t）比较寄存器rsl和rs2中的值（采用二进制补码表示），如果rsl中的值较小则跳转。大于等于分支（bge）指令是相反情况，也就是说，如果rsl中的值至少不小于rs2中的值则跳转。无符号的小于则分支指令（b1tu）意味着，如果二者是无符号数，那么rsl中的值小于rs2中的值则跳转。最后，无符号数的大于等于则分支指令（bgeu)在相反的情况下跳转。

另一种提供这些额外分支指令的方法是根据比较结果设置寄存器，然后使用beq或bne指令根据该临时寄存器中的值来进行分支判断。这种由MIPS指令系统使用的方法可以使处理器数据通路稍微简单一些，但它需要更多指令来表达程序。

ARM指令系统使用的另一种方法是，保留额外的位来记录指令执行期间发生的情况。这些额外的位称为条件代码或标志位，用于表明例如算术运算的结果是否为负数或零，或溢出。条件分支利用这些条件代码的组合来执行期望的判断。条件代码的一个缺点是，如果许多指令总是设置它们，则会生成让流水线执行困难的依赖关系（参见第4章）。

- 边界检查的简便方法

	将有符号数当作无符号数处理，给我们提供了一种低成本的方式检查是否0≤x<y，常用于检测数组下标是否越界。关键在于二进制补码表示中的负整数看起来像无符号表示中很大的数；因为最高有效位在有符号数中表示符号位，但在无符号数中表示数的很大一部分。因此，无符号比较x<y在检测x是否小于y的同时，也检测了x是否为负数。

==== case/switch语句

两种方法：

1. 将case/switch语句转换为if-then-else语句

2.  使用分支地址表。程序索引到地址表中，然后跳转到对应的地址。

	编码形成指令序列的地址表，称为分支地址表或分支表，程序只需要索引到表中，然后跳转到合适的指令序列。因此，分支表只是一个字数组，其中包含与代码中的标签对应的地址，该程序将分支表中的相应条目加载到寄存器中。然后需要使用寄存器中的地址进行跳转。为了支持这种情况，RISC-V这类指令系统包含一个间接跳转指令，该指令对寄存器中指定的地址执行无条件跳转。在RISC-V中，跳转-链接指令（jalr）用于此目的。

	分支地址表：也称作分支表，一种包含了不同指令序到地经的表。

=== 计算机硬件对函数的支持

过程(procedure)或函数是编程人员用于结构化编程的一种工具，两者均有助于提高程序的可理解性和代码的可重用性。过程允许程序员一次只专注于任务的一部分；参数可以传递数值并返回结果，因此用以充当过程和其余程序与数据之间的接口。

过程是用软件实现抽象的一种方式。可以把过程想象成一个携带秘密计划离开的侦探，他获取资源，执行任务，掩盖踪迹，然后带着预期结果返回原点。一旦任务完成，则再无任何干扰。更重要的是，侦探只在“需要知道”的基础上运作，因此侦探不能对雇主同样，在执行过程时，程序必须遵循以下六个步骤：

1. 将参数放在过程可以访问的位置
2. 将控制转交给过程（函数）
3. 获得过程所需的储存资源
4. 执行任务
5. 将结果放在调用程序可以访问的位置
6. 将控制返回初始点

过程:

	一个根据给定参教执行特定任务的已存储的子程序。

跳转一链接指令:

	政转到某个地址的同时得下一条指今的地址保存在寄存器（在RISC-V中还常是x1）中的指令。

==== 使用更多的寄存器

假设对于一个过程，编译器需要比8个参数寄存器更多的寄存器。由于在任务完成后必须掩盖踪迹，调用者所需的所有寄存器都必须恢复到调用该过程之前所存储的值。换出寄存器的理想数据结构是栈（stack）——一种后进先出的队列。栈需要一个指向栈中最新分配地址的指针，以指示下一个过程应该放置换出寄存器的位置或寄存器旧值的存放位置。在RISC-V中，栈指针(stack pointer)是寄存器x2.也称为sp。栈指针按照每个被保存或恢复的寄存器按字进行调整。栈应用非常广泛，因而传送数据到栈或从栈传输数据都具有专业术语：将数据放人栈中称为压栈，从栈中移除数据称为弹栈。

按照历史惯例，栈按照从高到低的地址顺序“增长”。这就意味着可以通过减栈指针将值压栈；通过增加栈指针缩小栈，从而弹出栈中的值。

在运行过程（函数）时，在栈中存储局部变量，在堆中存储常量和静态变量


栈:
	
	一种被组织成后进先出队列并用于寄存器换出的数据结构。

栈指针：

	指示栈中最新分配的地址的值，用于指示应该被换出的寄存器的位置，或寄存艺旧值的存放位置。在RISC-V中为齐存器sp或x2。

压栈：

	向栈中添加元素。
	
弹楼：

	从栈中移除无素。

==== 嵌套过程

不调用其他过程的过程称为叶子（leaf）过程。如果所有过程都是叶子过程，情况将会变得简单，但事实并非如此。正如一个侦探任务的一部分可能是雇佣其他侦探一样，被雇佣的侦探进而雇佣更多的侦探，过程调用其他过程也是如此。更进一步，递归过程甚至调用的是自身的“克隆”。就像在过程中使用寄存器时需要小心一样，在调用非叶子过程时必须更加注意。

一种解决方法是将其他所有必须保存的寄存器压栈，就像保存寄存器压栈一样。调用者将所有调用后还需要的参数寄存器(x10-x17）或临时寄存器(x5-×7和×28-×31)压栈。被调用者将返回地址寄存器x1和被调用者使用的保存寄存器(x8~x9和x18~x27)压栈。调整栈指针sp以计算压栈寄存器的数量。返回时，从存储器中恢复寄存器并重新调整栈指针。

==== 在栈中为新数据分配空间

TIP: 详细附图说明或删除

==== 在堆中为新数据分配空间

TIP: 详细附图说明或删除

=== 并行性与指令：同步

当任务之间相互独立时，并行执行更为容易，但通常任务之间需要协作。协作通常意味着一些任务正在写人其他任务必须读取的值。需要知道任务何时完成写人以便其他任务安全地读出，因此任务之间需要同步。如果它们不同步，则存在数据竞争（data race)的危险，那么程序的结果会根据事件发生的次序而改变。

在计算中，同步机制通常由用户级的软件例程所构建，而这依赖于硬件提供的同步指令。加锁和解锁可直接用于创建只有单个处理器可以操作的区域，称为互斥(mutual exclusion)区，以及实现更复杂的同步机制。

在多处理器中实现同步所需的关键是一组硬件原语，能够提供以原子方式读取和修改内存单元的能力。也就是说，在内存单元的读取和写入之间不能插人其他任何操作。如果没有这样的能力，构建基本同步原语的成本将会很高，并会随着处理器数量的增加而急剧增加。

有许多基本硬件原语的实现方案，所有这些都提供了原子读和原子写的能力，以及一些判断读写是不是原子操作的方法。通常，体系结构设计人员不希望用户使用基本的硬件原语，而是期望系统程序员使用原语来构建同步库，这个过程通常复杂且棘手。

原子交换(atomic exchange或atomic swap)原语是构建同步机制的一种典型操作，会将寄存器中的值与存储器中的值进行交换。为了了解如何使用它来构建基本同步原语，假设要构建一个简单的锁变量，其中值0用于表示锁变量可用，值1用于表示锁变量已被占用。处理器尝试通过将寄存器中的1与该锁变量对应的内存地址的值进行交换来设置加锁。如果某个其他处理器已声明访问该锁变量则交换指令的返回值为1，表明该锁已被其他处理器占用，否则为0，表示加锁成功。在后一种情况下，锁变量的值变为1，以防止其他处理器也加锁成功。

例如，考虑两个处理器尝试同时进行交换操作：这种竞争会被阻止，因为其中一个处理器将首先执行交换，并返回0，而第二个处理器在进行交换时将返回1。使用交换原语实现同步的关键是操作的原子性：交换是不可分割的，硬件将对两个同时发生的交换进行排序。尝试以这种方式设置同步变量的两个处理器都不可能认为它们同时设置了变量。

实现单个的原子存储操作为处理器的设计带来了一些挑战，因为它要求在单条不可中断的指令中完成存储器的读和写操作。

另一种方法是使用指令对，其中第二条指令返回一个值，该值表示该指令对是否被原子执行。如果任何处理器执行的所有其他操作都发生在该对指令之前或之后，则该指令对实际上是原子的。因此，当指令对实际上是原子操作时，没有其他处理器可以在指令对之间改变值。在RISC-V中，这对指令指的是一个称为保留加载（load-reserved）字（1r.w)的特殊加载指令和一个称为条件存储(store-conditional）字(sc.w）的特殊存储指令。这些指令按序使用：如果保留加载指令指定的内存位置的内容在条件存储指令执行到同一地址之前发生了变化，则条件存储指令失败且不会将值写入内存。条件存储指令定义为将（可能是不同的）寄存器的值存储在内存中，如果成功则将另一个寄存器的值更改为0.如果失败则更改为非零值。因此，SC.w指定了三个寄存器：一个用于保存地址，一个用于指示原子操作失败或成功，还有一个用于如果成功则将值存储在内存中。

=== 翻译并启动程序

[cols="1,1", options="header"]
|===
| 工具 | 作用

| 编译器 (Compiler)
| 将高级语言（如C、C++）源代码转换成中间代码或机器代码。编译器负责语法分析、语义分析、优化和目标代码生成。它生成一个独立的可执行文件，通常为机器语言指令，供计算机直接执行。

| 汇编器 (Assembler)
| 将汇编语言代码转换成机器代码或目标代码。汇编器负责将汇编语言的每条指令映射为相应的机器指令。它处理符号（如标签和变量）并生成对应的机器代码文件（通常是`.obj`文件）。

| 链接器 (Linker)
| 将多个目标文件（通常是由编译器或汇编器生成的）和库文件结合在一起，生成一个可执行文件。链接器负责解决符号引用、地址分配和代码重定向，使程序中的函数和变量能够正确地互相引用。

| 加载器 (Loader)
| 将可执行文件加载到内存中并准备执行。加载器将程序的各个部分（如代码段、数据段）载入内存，并将控制权交给操作系统或程序的入口点，开始执行程序。它还可能进行地址重定位，确保程序在内存中正确运行。
|===


编译器、汇编器、链接器和加载器是计算机程序开发过程中密切协作的四个关键工具，它们分别承担不同的角色，并且在程序生成和执行过程中依赖彼此的工作。编译器是程序开发的第一步，它将高级语言（如C语言）源代码转换为汇编语言或中间代码。汇编器接下来会将编译器生成的汇编代码转换为机器代码或目标代码，产生可供计算机理解的低级语言。生成的目标代码通常是一个或多个独立的文件，但这些文件还不能直接执行，因为它们可能包含未解析的符号或地址引用。链接器接管这个任务，它将多个目标文件和库文件合并成一个完整的可执行文件，并解决其中的符号引用，调整内存地址，确保所有函数和数据能够正确链接和引用。

当程序准备好并生成了可执行文件之后，加载器的工作就开始了。加载器负责将可执行文件加载到内存中，并将程序控制权交给操作系统或程序的入口点，从而启动程序的执行。在加载过程中，加载器可能还会进行地址重定位，确保程序能够在内存的不同位置运行。总的来说，编译器、汇编器、链接器和加载器共同协作，将开发者编写的高级程序转化为最终可在计算机上运行的可执行文件，并确保程序的各个部分能够正确连接和执行。

TIP:附图p90

==== 动态链接库

TIP: 对照书内容p94

动态链接库（Dynamic Link Library，简称DLL）是一种在程序运行时动态加载和链接的库文件。与静态链接库不同，动态链接库在程序编译时并不直接包含进可执行文件，而是在程序运行时根据需要加载到内存中。DLL文件通常包含一组函数、数据或资源，供其他程序或模块在执行过程中调用。这种方式能够实现模块化的编程，多个程序可以共享同一个DLL文件，从而减少内存和磁盘空间的占用。

动态链接库的主要作用是提供程序功能的共享和扩展。通过将常用的功能封装在DLL中，开发者可以避免重复编写相同的代码，并且在程序运行时可以灵活地加载和调用这些功能。当多个程序需要相同的功能时，它们可以共享同一个DLL，避免每个程序都包含一份相同的代码，这样不仅节省了资源，还使得程序的更新和维护变得更加简便。通过更新DLL文件中的代码，所有使用该库的程序都能够自动获得更新，而无需重新编译和发布每个程序。

此外，动态链接库还提供了运行时的灵活性。程序可以根据需求加载和卸载DLL，使得系统能够更有效地管理内存。它还支持程序的插件式架构，允许在不修改主程序的情况下添加新的功能或模块，从而提升了程序的可扩展性和维护性。

== 计算机的算术运算

=== 加法和减法

加法是数字从右到左逐位相加，并将进位传送到左侧的下一位数字，与手动计算一样。减法也使用加法实现：相应操作数被简单取反后再进行加法操作。

==== 加法与减法的溢出判断

由于硬件规模总是有一定限制的，比如字宽为32位，当运算结果超过这个限制时，就会发生溢出。在加法中何时会发生溢出？当不同符号的操作数相加时，不会发生溢出。因为总和一定不会大于其中任意一个操作数。例如，stem:[-10+4=-6]。由于操作数可以表示成32位且其总和不大于任一操作数，所以总和也一定能表示成32位。因此，当正负操作数相加时不会发生溢出。在减法中也有类似的不会发生溢出的情况，但原理相反：当操作数的符号相同时，不会发生溢出。为了说明这一点，需要记住stem:[c-a=c+(-a)]，这是因为我们通过将第二个操作数取反然后相加来实现减法。因此，当相同符号的操作数相减时，最终会变成相反符号的操作数相加。从上一段落可知，在这种情况下不会发生溢出。知道加法和减法运算在什么时候不会发生溢出固然很好，但如何检测它何时发生呢？显然，加或减两个32位的数字可能产生一个需要33位才能表示的结果。缺少第33位意味着当溢出发生时，符号位被结果的值占用而非结果的正确符号。由于溢出结果只可能多一位，所以只有符号位可能是错误的。因此，当两个正数相加但和为负数时，说明发生了溢出，反之亦然。这个假的和值意味着产生了向符号位的进位。

当出现了不合理的运算结果时，意味着发生了溢出。下表展示了溢出发生时的运算、操作数和运算结果。

[options="header"]
|====
|操作 | 操作数A | 操作数B | 表明溢出的结果

|stem:[A+B]
|stem:[\ge 0]
|stem:[\ge 0]
|stem:[< 0]

|stem:[A+B]
|stem:[< 0]
|stem:[< 0]
|stem:[\ge 0]

|stem:[A-B]
|stem:[\ge 0]
|stem:[< 0]
|stem:[< 0]

|stem:[A-B]
|stem:[< 0]
|stem:[\ge 0]
|stem:[\ge 0]

|====

无符号整数通常用于表示忽略溢出的内存地址。计算机的有限字长意味着算术运算可能会产生过量而无法用这种固定字长表示的运算结果，即发生溢出。虽然无符号数的溢出容易检测，但无符号数通常使用自然数做地址运算，而程序通常不需要检测地址计算的溢出，所以这些溢出总被忽略。

=== 乘法

==== 串行版的乘法运算及其硬件实现

TIP: P134三张图

该设计模仿了我们在小学学到的算法，上图展示了该设计的硬件结构。假设乘数位于32位乘法器寄存器中，并且将64位乘积寄存器初始化为0。我们需要在每一步计算中将被乘数左移一位，因为它可能会和之前的中间结果相加。在32步计算之后，32位被乘数会向左移动32位。因此，我们需要一个64位的被乘数寄存器，将其初始化为右半部分的32位被乘数和左半部分的零。然后该寄存器每执行一步便左移1位，将被乘数与64位的乘积寄存器中的中间结果对齐并累加到中间结果。

TIP: 1

下图显示了对于操作数的每一位都需要做的三个基本步骤。第一步中的乘数最低位（乘数第0位）决定了是否要把被乘数加到积寄存器当中。第二步中的左移起着将中间操作数左移的作用，就像手工计算做乘法一样。第三步中的右移给出了下次迭代要检测的乘数的下一位。这三个步骤重复32次就会得到最后的积。如果每个步骤花费一个时钟周期，那么该算法计算两个32位数相乘差不多要花费200个时钟周期。像乘法这样的算术运算的重要性随程序的不同而变化，但一般加法和减法出现的次数会是乘法的5到100倍。因此，在许多应用中，乘法花费若干时钟周期并不会显著影响性能。但是，Amdahl定律提醒我们，一个慢速操作如果占据了一定的比例，也会限制程序性能。
TIP: 2
这种算法和硬件很容易改进到每步只花费一个时钟周期。加速来源于操作的并行执行：如果乘数位是1.那么对被乘数和乘数进行移位，与此同时，把被乘数加到积上。硬件只需要保证它检测的是乘数的最右位，而且得到的是被乘数移位前的值。注意到寄存器和加法器有未使用的部分后，通常会将加法器和寄存器的位长减半以进一步优化硬件结构。下图展示了修正后的硬件。

TIP: 3

==== 带符号乘法

对于如何处理带符号乘法，最简单的方式是先把被乘数和乘数转换为正数，然后记住它们的初始符号。这样，将之前的算法迭代执行31次，符号位不参与计算。正如我们小学学到的那样，只有在乘数和被乘数符号相反时，对积取反。事实证明，如果记住我们正在处理具有无限位长的数，并且只用32位来表示它们，则上面的最后一种算法适用于带符号数。因此，在移位时需要对带符号数的积进行符号扩展。当算法结束时，低位的双字就是32位积。

==== 快速乘法

摩尔定律提供了非常充足的资源，从而使硬件设计人员可以实现更快的乘法硬件。通过在乘法运算开始的时候检查32个乘数位，就可以判定是否要将被乘数加上。快速乘法可以通过为每个乘数位提供一个32位加法器来实现：一个输入是被乘数和一个乘数位相与的结果，另一个输入是上一个加法器的输出。一种简单的方法是将右侧加法器的输出端连接到左侧加法器的输入端，形成一个高64位的加法器栈。另一种方式是将这32个加法器组织成如下图所示的并行树。这样我们就只需要等待stem:[log_2(32)]，即5次32位长加法的时间，而不是32次。

TIP: p136

由于使用进位保留加法器，乘法的速度甚至比5次加法还要快，并且因为容易将上述设计流水化，它能够同时支持多个乘法。

==== RISC-V中的乘法

为了产生正确带符号或无符号的64位积，RISC-V有四条指令：乘（mul），乘法取高位（mulh)，无符号乘法取高位（mulhu)，有符号/无符号乘法取高位（mulhsu）。要获得整数32位积，应使用mu1指令。要想得到64位积的高32位，如果两个操作数都是有符号的，应使用mulh指令；如果两个操作数都是无符号的，则使用mulhu指令；如果一个操作数是有符号的而另一个是无符号的，则使用mulhsu指令。

=== 除法

==== 除法运算及其硬件实现

下图展示了模拟基本除法算法的硬件。在开始时将32位的商寄存器置0.算法的每次迭代都需要将除数右移一位，因此开始需要将除数放置到64位的除数寄存器的左半部分，并且每运算一步并将其右移1位，使之与被除数对齐。余数寄存器初始化为被除数。

TIP: p138 1

下图展示了第一个除法算法的三个步骤。与人不同，计算机没有聪明到能预先知道除数是否小于被除数。它必须先在步骤1中用被除数减去除数，这正是我们实现比较所使用的方式。如果结果是正数或0，则除数小于或等于被除数，所以在商中生成一位1(步骤2a)。如果结果为负，则下一步是通过将除数加回余数来恢复原始值，并在商中生成一位0（步骤2b）。除数右移，然后再次迭代。在迭代完成后，余数和商将存放在其同名的寄存器中。

TIP: p138 2

这个算法及其硬件结构可以被改进得更快且更便宜。通过操作数移位和商与减法同时进行来加速。该细化包括注意哪里有未使用的寄存器和将加法器和寄存器宽度减半。图3-11展示了修改后的硬件。

TIP: p139 1

==== 有符号除法

计算机中的有符号除法是一种处理带符号整数的除法运算方法，能够正确处理正数和负数之间的除法关系。其核心思想是对符号和数值分别处理，以确保结果的符号正确，并在运算过程中避免符号干扰。以下是处理有符号除法的主要步骤。

首先，确定被除数和除数的符号。通过检查两数的符号位（通常是最高有效位），判断它们是否为正数或负数。如果符号相同（两者均为正或均为负），最终的商为正；如果符号不同（一个为正，一个为负），最终的商为负。这一步确定了商的符号，同时便于后续操作只处理数值部分。

接着，将被除数和除数的数值部分转换为绝对值进行处理。通过忽略符号位，可以将负数转化为正数，从而将后续的计算简化为无符号除法。随后，计算绝对值的商和余数，这通常是通过硬件或软件实现的无符号整数除法算法完成的。

在计算得到商和余数后，需要恢复结果的符号。商的符号按照第一步的判断进行设置，即根据被除数和除数符号是否相同来决定正负号。余数的符号通常与被除数相同，以保持数学意义上的一致性。

最后，将符号恢复后的商和余数作为最终结果返回。这个过程确保了除法运算能够正确处理正负数之间的关系，同时保持了计算机中带符号整数的标准表示方式。

==== 快速除法

摩尔定律适用于除法硬件以及乘法运算，所以希望能够通过其硬件来加速除法。通过使用许多加法器来加速乘法，但不能对除法使用相同的方法。因为在执行下一步运算之前，需要先知道减法结果的符号，而乘法运算可以立即计算32个部分积。有些技术每步可以产生多于一位的商。SRT除法技术试图根据被除数和余数的高位来查找表，以预测每步的多个商的位数。它依靠后续步骤纠正错误预测。今天的典型值是4位。关键在于猜测要减去的值。对于二进制除法，只有一个选择。这些算法使用余数的6位和除数的4位来索引查找表，以确定每个步骤的猜测。

这种快速方法的准确性取决于查找表中的值是否合适。3.9节中的谬误展示了如果表不正确将会发生什么情况。

==== RISC-V中的除法

上文中提到的乘法与除法都可以使用相同的顺序执行硬件。唯一需要的是一个可以左右移位的64位寄存器和一个实现加法或减法的32位ALU。

为了处理有符号整数和无符号整数，RISC-V有两条除法指令和两条余数指令：除（div），无符号除(divu)，余数（rem），无符号余数（remu）。

=== 浮点运算

浮点数的表示基于科学计数法的思想，将数值拆分为三个部分：符号、尾数和指数，从而能够在有限的存储空间内表示非常大的数值范围和较高的精度。浮点数的运算原理涵盖其表示方式、对齐、计算和规范化等多个步骤。

浮点数通常采用IEEE 754标准表示。一个浮点数由符号位、指数部分和尾数部分组成。符号位决定数值是正还是负；指数部分采用偏移表示法（通常为偏移值加上实际指数），用来表示浮点数的数量级；尾数部分存储有效数字，并隐含一个固定的基数（如2或10），构成完整的数值表示。

在浮点运算中，首先需要对操作数进行对齐。对齐是指通过调整指数，使得两数的指数部分相同，从而保证尾数能够直接参与加法或减法运算。对齐时，较小指数的数值会通过右移尾数来提升指数，可能会丢失部分精度。接下来，计算器会执行尾数的加法、减法、乘法或除法操作，具体过程与整数运算类似，但需要对结果进行额外的处理以符合浮点数的格式。

运算完成后，结果可能需要进行规范化和舍入。规范化是指调整尾数和指数，使尾数的最高位为非零，以便最大限度利用存储精度。如果尾数超出浮点数的表示范围，则需要通过调整指数来缩放结果。舍入是为了处理由于尾数截断而导致的误差，常用的舍入方式包括向上取整、向下取整或最近值舍入。

浮点运算还需要处理特殊情况，如零、无穷大和非数字（NaN）。这些特殊值由IEEE 754标准定义，用于应对计算中的异常情况。浮点数运算的复杂性主要来自于其需要在保持数值范围和精度之间取得平衡，因此需要硬件和算法的高效支持。浮点运算广泛应用于科学计算、图形处理和工程模拟中，是计算机实现高精度数值计算的重要基础。

==== 浮点表示

浮点表示的设计者必须在尾数的位数大小和指数的位数大小之问找到一个平衡，因为固定的字大小意味着若一部分增加一位，则另一部分就得减少一位。即要做精度和范围之间的权衡：增加尾数位数的大小可以提高小数精度，而增加指数位数的大小则可以增加数的表示范围。

浮点数通常占用多个字的长度。下图是RISC-V浮点数的表示方法，其中S是浮点数的符号（l表示负数），指数由8位指数字段（包括指数的符号）表示，尾数由23位数表示。正如第2章提过的那样，这种表示称为符号和数值，符号与数值的位是相互分离的。

TIP: p143图

通常来讲，浮点数可以这样表示：

[stem]
++++
(-1)^S \times F × 2^E
++++

F是尾数字段中表示的值，而E是指数字段表示的值。

这些指定的指数和尾数位长使RISC-V计算机具有很大的运算范围。小到stem:[2.0_{10} \times 10^{-38}]，大到stem:[2.0_{10} \times 10^{38}]，计算机都能表示出来。但是它和无穷大不同，所以仍然可能存在数太大而表示不出来的情况。因此，和整点运算一样，浮点运算中也会发生溢出例外。注意这里的溢出表示因指数太大而无法在指数字段中表示出来。

浮点运算还会导致出现一种新的例外情况。正如程序员想知道他们什么时候计算了一个难以表示的太大的数一样，他们还想知道他们正在计算的非零小数是否变得小到无法表示，这两个事件都可能导致程序给出不正确的答案。为了和上溢区分开来，我们把这种情况称为下溢。当负指数太大而指数字段无法表示时，就会出现这种情况。

减少下溢或上溢发生概率的一种方法是提供另一种具有更大指数范围的格式。在C语言中，这个数据类型称为双精度（double）.基于双精度的运算称为双精度浮点运算，而单精度浮点就是前面介绍的格式。

双精度浮点数需要一个RISC-V双字才能表示，如下所示，其中S仍然是数的符号位。指数字段为11位，尾数字段为52位。

TIP: p144

RISC-V双精度可以表示的实数范围小到stem:[2.0_{10} \times 10^{-308}]，大到stem:[2.0_{10} \times 10^{308}]。尽管双精度确实增加了指数字段能表示的范围，但其最主要的优点是由于有更大的尾数位数而具有更高的精度。

==== 例外和中断

在上溢或下溢时应该让计算机发生什么以让用户知道出现了问题?有些计算机会通过引发例外（有时也称作中断）来告知问题的出现。例外或中断在本质上是一种非预期的过程调用。造成溢出的指令的地址保存在寄存器中，并且计算机会跳转到预定义的地址以调用相应的例外处理程序。中断的地址被保存下来，以便在某些情况下可以在执行纠正代码之后继续执行原程序。RISC-V计算机不会在上溢或下溢时引发例外，不过，软件可以读取浮点控制和状态寄存器(fcsr)来检测是否发生上溢或下溢。

==== IEEE754浮点数标准

IEEE 754 是一种广泛应用于计算机系统的浮点数标准，旨在规范浮点数的表示、运算、舍入和异常处理，使不同计算平台能够一致地处理实数运算。最初的标准于 1985 年发布，后续版本不断改进，支持更广泛的计算需求。以下是该标准的主要内容和特点：

- 浮点数的表示

IEEE 754 采用类似于科学计数法的形式表示浮点数，通过二进制分解为三个部分：符号位（Sign）、指数部分（Exponent）和尾数部分（Mantissa，又称有效位）。浮点数表示的通用公式为：
[stem]
++++
N = (-1)^S \times F × 2^E
++++
其中：

S：符号位，表示数值的正负。0 为正数，1 为负数。

E：指数部分，使用偏移表示法存储。实际指数通过 E_actual = E_stored - bias 计算，bias 是一个偏移值。

M：尾数部分，表示有效数字的二进制小数。标准规定隐含一个整数部分，通常为1。
 
- 特殊值的表示
IEEE 754 设计了特殊值来表示异常或边界情况：

1. 零：符号位可以是0或1，指数部分全为0，尾数全为0。
2. 无穷大（Infinity）：符号位表示正负，指数部分全为1，尾数全为0。
3. 非数字（NaN，Not a Number）：用于表示未定义或无效的结果，如 0/0。指数部分全为1，尾数非零。
4. 非规格化数（Denormalized Number）：当指数部分为0且尾数非零时，表示非常接近零的小数。

- 舍入模式
IEEE 754 提供了多种舍入模式，用于解决尾数截断引发的误差：

向最近值舍入（默认）
向零舍入
向正无穷大舍入
向负无穷大舍入

TIP: 补充or删除

==== 浮点加法
==== 浮点乘法
==== RISC-V中的浮点指令
==== 精确算术

=== 并行性与计算机算术

通过划分进位链，可以同时对多个短向量进行并行操作。即数据级并行

由于手机、平板电脑或笔记本电脑中的每个微处理器都有自己的图形显示器，随着晶体管数量的增加，对于图形操作的支持也不可避免地会增加。

许多图形系统最初使用8位数据来表示三原色中的一种，外加8位来表示一个像素的位置。在电话会议和视频游戏中添加了扬声器和麦克风对声音进行支持。音频采样需要8位以上的精度，但16位精度就已经足够了。

所有微处理器都对字节和半字有特殊支持，使其在存储时占用更少的存储器空间，但在典型的整数程序中对这类大小数据的算术运算非常少，因此几乎不支持除数据传输之外的其他操作。架构师发现，许多图形和音频应用会对这类数据的向量执行相同操作。通过在128位加法器内划分进位链，处理器可以同时对16个8位操作数、8个16位操作数、4个32位操作数或2个64位操作数的短向量进行并行操作。

这种分割加法器的开销很小，但带来的加速可能很大。

将这种在一个宽字内部进行的并行操作称为子字并行(subword parallelism)。更通用的名称是数据级并行(data level parallelism)。对于单指令多数据，它们也被称为向量或SIMD。多媒体应用程序的逐渐普及促使了支持易于并行计算的窄位宽操作的算术指令的出现。

== 处理器

=== 单周期处理器实现


实现一个单周期处理器需要多个关键模块协同工作，以便在一个时钟周期内完成指令的取指、译码、执行、存储访问和写回操作。这些模块包括控制单元、寄存器文件、算术逻辑单元（ALU）、程序计数器（PC）、指令存储器、数据存储器以及各种多路选择器（MUX）和信号通路（Bus）。

- 程序计数器（PC）

	程序计数器存储当前指令的地址，并在每个时钟周期自动更新以指向下一条指令。PC的输出作为指令存储器的输入地址。对于跳转或分支指令，PC的值可能由控制单元计算并更新。

- 指令存储器

	指令存储器根据 PC 提供的地址，输出当前指令的二进制码。指令由操作码（opcode）、寄存器地址（源寄存器、目标寄存器）和立即数等字段组成，这些字段作为后续模块的输入。

- 控制单元

	控制单元负责解析指令的操作码，生成控制信号以指导其他模块的行为。例如：
	决定 ALU 执行的操作（加、减、逻辑运算等）。
	控制数据存储器的读写行为。
	控制寄存器文件的数据读写方向。
	选择跳转或分支地址。
	控制单元的输出信号连接到 ALU、数据存储器、多路选择器和其他模块。

- 寄存器模块

	寄存器模块存储处理器的操作数。它包含多个通用寄存器：
	根据指令的源寄存器字段，从寄存器文件中读取操作数。
	根据目标寄存器字段，将计算结果写回寄存器文件。
	寄存器文件的读写操作由控制单元生成的控制信号控制。

- 算术逻辑单元（ALU）

	ALU 执行算术和逻辑运算，例如加法、减法、位与、位或等。它的输入操作数来自寄存器模块或立即数，具体取决于指令类型（R 型、I 型等）。ALU 的输出即为运算结果，通常存储回寄存器文件或用于分支条件的判断。

- 数据存储器

	数据存储器用于加载或存储数据，支持内存读写操作：
	加载指令（如 lw）从数据存储器读取数据，并将其送入寄存器文件。
	存储指令（如 sw）将寄存器文件中的数据写入数据存储器。
	数据存储器的地址和数据由指令字段和 ALU 的运算结果决定，其读写行为由控制信号控制。

- 多路选择器（MUX）

	多路选择器用于在多种可能的输入中选择一个作为输出。主要用途包括：
	在立即数和寄存器操作数之间选择 ALU 输入。
	在 ALU 输出和数据存储器输出之间选择寄存器写入的数据。
	在顺序地址和跳转目标地址之间选择 PC 的下一个值。

- 信号通路和总线

	信号通路用于连接各个模块，允许数据和控制信号在模块之间流动。总线是一种共享的通信通道，可用于传递指令、数据或地址。

TIP: p176

通过这些模块的紧密配合，单周期处理器能够在一个时钟周期内完成一条指令的全部执行过程。虽然结构简单，但由于所有操作都必须在单个周期内完成，其性能受限于最慢路径的延迟。

==== 逻辑设计的基本方法

RISC-V实现中的数据通路包含两种不同类型的逻辑单元：处理数据值的单元和存储状态的单元。处理数据值的单元是组合逻辑，它们的输出仅依赖于当前输人。给定相同的输人，组合逻辑单元总是产生相同的输出。例如，ALU就是一个组合逻辑单元。由于组合逻辑单元没有内部存储功能，当给定一组输人时，它总是产生相同的输出。

设计中的其他单元不是组合逻辑，而是包含状态的。如果一个单元有内部存储功能，它就包含状态，称其为状态单元。这是因为关机后重启计算机，通过恢复状态单元的原值，计算机可继续运行，就像没有发生过断电一样。进一步地，这些状态单元可以完整地表征计算机。例如，指令存储器、数据存储器以及寄存器都是状态单元。

一个状态单元至少有两个输人和一个输出。必需的输入是要写入状态单元的数据值和决定何时写入数据值的时钟信号。状态单元的输出提供了在前一个时钟周期写入单元的数据值。例如，逻辑上最简单的一种状态单元是D触发器，它有两个输入(一个数据值和一个时钟）和一个输出。除了触发器，RISC-V的实现中还用到了另外两种状态单元：存储器和寄存器。状态单元何时被写入由时钟确定，但是它随时可以被读。

包含状态的逻辑部件也被称为时序的，因为其输出取决于输人和内部状态。例如，表示寄存器的功能单元的输出取决于所提供的寄存器号和之前写人寄存器的内容。

**时钟同步方法**

时钟同步方法（clocking methodology）规定了信号可以读出和写入的时间。规定信号的读写时间非常重要，因为如果在读信号的同时写信号，那么读到的值可能是该信号的旧值，也可能是新写入的值，甚至可能是二者的混合。计算机设计无法容忍这种不可预测性。时钟同步方法就是为避免这种情况而提出的。

为简单起见，假定我们采用边沿触发的时钟(edge-triggered clocking)，即存储在时序逻辑单元中的所有值仅在时钟边沿更新，这是从低电平快速跳变到高电平（反之亦然）的过程。因为只有状态单元能存储数据值，所有组合逻辑单元都必须从状态单元集合接收输入，并将输出写入状态单元集合。其输入是之前某时钟周期写入的值，输出的值可以在后续时钟周期使用。

==== 数据通路

数据通路是计算机处理器中一个核心的硬件部分，专门用于传输、存储和处理指令和数据。它由寄存器、算术逻辑单元（ALU）、多路选择器（MUX）、数据总线、存储器等模块组成，负责在指令执行过程中完成数据的流动和运算操作。数据通路通过硬件资源的协同工作，将指令的每个步骤具体化，从而实现处理器功能。

数据通路的作用是完成指令执行的全部过程，包括指令的取指、译码、执行、存储访问和写回操作。通过程序计数器（PC），数据通路能够确定当前指令的位置并从指令存储器中读取；通过寄存器文件和 ALU，数据通路可以完成算术和逻辑运算；通过多路选择器和数据总线，数据通路能在不同的硬件模块之间高效地传递数据；通过数据存储器，数据通路支持加载和存储操作。它的设计决定了处理器的性能、效率和指令支持能力，是实现计算任务的硬件基础。

==== 单周期处理器的实现

TIP: 待定

==== 为什么现在不使用单周期实现

尽管单周期设计可以正确工作，但是在现代设计中不采取这种方式，因为它的效率太低。究其原因，是在单周期设计中时钟周期对于每条指令必须等长。这样，处理器中的最长路径决定了时钟周期。这条路径很可能是一条load指令，它连续地使用5个功能单元：指令存储器、寄存器堆、ALU、数据存储器和寄存器堆。虽然CP1为1（见第1章），但由于时钟周期太长，单周期实现的整体性能可能很差。使用单周期设计的代价是显著的，但对于这个小指令集而言，或许是可以接受的。历史上，早期具有简单指令集的计算机确实采用这种实现方式。但是，如果要实现浮点单元或更复杂的指令集，单周期设计根本无法正常工作。由于时钟周期必须满足所有指令中最坏的情况，所以不能使用那些缩短常用指令执行时间而不改变最坏情况的实现技术。因此，单周期实现违反了第1章中加速经常性事件这一设计原则。在4.6节，我们将看到一种称为流水线的实现技术，它使用与单周期相似的数据通路，但吞吐量更高，效率更高。流水线技术通过同时执行多条指令来提高效率。

=== 多周期实现

在多周期实现中，执行中的每一步都需要1个时钟周期。多周期实现允许每个指令多次使用同一个功能单元，只要它在不同的时钟周期内使用。这种共享有助于减少所需的硬件数量。允许指令采用不同数量的时钟周期，以及在单条指令的执行中共享功能单元是多周期设计的主要优势。虽然多周期实现可以降低硬件成本，但今天几乎所有的芯片都使用流水线来提高性能。

多周期处理器是一种通过将指令执行过程划分为多个阶段、在多个时钟周期内完成的处理器设计。相比单周期处理器，多周期处理器可以在不需要重复硬件资源的情况下完成指令执行，从而实现更高的硬件利用率和更灵活的设计。其主要组成模块包括控制单元、程序计数器（PC）、指令存储器、寄存器文件、算术逻辑单元（ALU）、数据存储器和多路选择器等。

多周期处理器的工作流程通过阶段化的方式逐步完成每条指令的执行。首先，程序计数器提供当前指令的地址，指令存储器根据地址取出指令并送入控制单元。控制单元解析指令，生成对应的控制信号，引导寄存器文件从指定寄存器中读取操作数，同时为后续阶段设定路径。接下来，ALU 执行算术或逻辑运算，或者用于计算存储器的访问地址。对于加载或存储指令，ALU 的输出作为地址输入到数据存储器，数据存储器根据指令类型进行读写操作。最后，处理器将运算结果或者从存储器读取的数据写回寄存器文件，完成指令的执行。

在多周期处理器中，每个时钟周期只执行一部分工作，例如取指、译码、执行、存储访问或写回。这种设计允许同一硬件资源（如 ALU 或数据存储器）在不同阶段为不同指令使用，因此相较于单周期处理器，硬件资源需求更低。此外，多周期处理器的控制单元采用有限状态机（FSM）设计，根据当前指令的类型和执行阶段生成精确的控制信号，确保每个模块在正确的时间参与操作。

多周期处理器通过分阶段执行，平衡了性能与硬件资源之间的关系，使其适合于资源有限的系统设计，同时可以支持复杂指令集。然而，由于指令完成时间不固定，其性能通常低于流水线处理器，但更容易实现且硬件开销较低。

=== 流水线概述

流水线是一种能使多条指令重叠执行的实现技术。使用流水线来使指令能重叠执行，以提高性能。即指令级并行（ILP）。目前，流水线技术广泛应用。

下面使用一个比喻概述流水线的概念及相关问题。

任何做洗衣工作的人都不自觉地使用流水线技术。非流水线的洗衣过程包含如下步骤：

1. 将一批脏衣服放入洗衣机。

2. 洗衣机洗完后，将湿衣服取出并放入烘干机

3. 烘干机完成后，将干衣服取出，放在桌上并叠起来

4. 叠好后，请你的室友帮忙把衣服收好。

当这一批衣服收好后，再开始洗下一批脏衣服。

流水线方法花费的时间少得多。当第一批衣服从洗衣机中取出并放人烘干机后，就可以把第二批脏衣服放入洗衣机。当第一批衣服烘干完成后，就可以把它们放在桌上叠起来，同时把洗衣机中洗好的衣服放入烘干机，再将下一批脏衣服放入洗衣机。接着让你的室友把第一批衣服从桌上收好，你开始叠第二批衣服，烘干机开始烘干第三批衣服，同时可以把第四批衣服放人洗衣机。此时，所有的洗衣步骤（称为流水线阶段）在同时工作。只要每个阶段使用不同的资源，我们就可以用流水线的方法完成任务。

流水线的矛盾在于，对于一双脏袜子，从把它放人洗衣机到被烘干、叠好和收起的时间在流水线中并没有缩短；然而对于许多负载来说，流水线更快的原因是所有工作都在并行地执行。所以单位时间能够完成更多工作，流水线提高了洗衣系统的吞吐率（throughput)。因此，流水线不会缩短洗一次衣服的时间，但是当有很多衣物需要洗时，吞吐率的提高减少了完成整个任务的时间。

如果每个步骤需要的时间相同，并且要完成的工作足够多，那么由流水线产生的加速比等于流水线中步骤的数目，在这个例子中是4倍：洗涤、烘干、折叠和收起。因此，流水线方式洗衣是非流水线方式洗衣速度的4倍：流水线中20次洗衣需要的时间是一次洗衣的5倍，而20次非流水线洗衣的时间是一次洗衣的20倍。

同样的原则也可用于处理器，即采用流水线方式执行指令。RISC-V指令执行通常包含五个步骤：

1. 从存储器中取出指令。

2. 读寄存器并译码指令。

3. 执行操作或计算地址。

4. 访问数据存储器中的操作数（如有必要）。

5. 将结果写人寄存器（如有必要）。

因此，本章探讨的RISC-V流水线有五个阶段，正如流水线加速洗衣过程一样。

==== 面向流水线的指令系统设计

尽管上面的例子只是对流水线的简单介绍，但我们也能够通过它了解面向流水线设计的RISC-V指令系统。

第一，所有RISC-V指令长度相同。这个限制简化了流水线第一阶段取指令和第二阶段指令译码。在像x86这样的指令系统中，指令长度从1字节到15字节不等，流水线设计更具挑战性。现代x86架构在实现时，将x86指令转换为类似RISC-V指令的简单操作，然后流水化这些简单操作，而不是流水化原始的x86指令。

第二，RISC-V只有几种指令格式，源寄存器和目标寄存器字段的位置相同。

第三，存储器操作数只出现在RISC-V的load或store指令中。这个限制意味着可以利用执行阶段来计算存储器地址，然后在下一阶段访问存储器。如果可以操作内存中的操作数，就像在x86中一样，那么第三阶段和第四阶段将扩展为地址计算阶段、存储器访问阶段和执行阶段。

==== 流水线数据通路和控制

TIP: p205

==== 利用指令级并行的基本编译器技术

- 找出除维护循环的代码外互不相关的循环迭代，判定循环展开是有用的。

- 使用不同寄存器，以避免由于不同运算使用相同寄存器而造成的非必要约束（比如，名称依赖）。

- 去除多余的测试和分支指令，并调整循环终止与迭代代码。

- 通过观察不同迭代中的载人指令与存储指令互不相关，判定展开后的循环中的载人指令和存储指令可以交换位置。这一变换需要分析存储器地址，确认它们没有引用同一地址。

- 在保留必要的依赖，以得到与原代码相同的结果的前提下，对代码进行调度。

要进行所有这些变换，关键是要理解指令之间的依赖关系，而且要知道在这些关系下如何改变指令或调整指令的顺序。

有3种效果会限制循环展开带来的好处：

1. 每次展开操作分摊的开销降低；

2. 代码规模限制;

3. 编译器限制。

我们首先考虑循环开销问题。将循环展开4次时，它在指令之间产生了足够的并行性，可以在没有停顿周期的情况下调度循环。事实上，在14个时钟周期中，只有2个周期是循环开销：维护索引值的addt和终止循环的bne。如果将循环展开8次，这一开销将从每个元素1/2周期降低到1/4周期。

展开的第二个限制是代码规模的增长。对于较大规模的循环，代码规模的增长可能是一个问题，特别是当它会导致指令缓存缺失率上升时。

还有一个通常比代码规模更重要的因素，就是由于大量进行展开和调度而造成寄存器数量不足。由于在大段代码中进行指令调度而产生的这一副作用被称为寄存器紧缺（register pressure）。之所以会出现这种情况，是因为调度代码以增加IP时导致存活值的数量增加。在大量进行指令调度之后，可能无法将所有存活值都分配到寄存器中。尽管转换后的代码在理论上运行速度更快，但由于它会造成寄存器紧缺，所以可能会损失部分乃至全部收益。在没有展开循环时，分支就足以限制大量使用调度，所以寄存器紧缺几乎不会成为问题。但是，循环展开与大量调度结合起来却可能导致这一问题。在需要暴露更多独立指令序列的多发射处理器中，这个问题变得尤其具有挑战性，因为这些指令序列的执行可能是重叠的。一般来说，高级、复杂转换的应用导致现代编译器的复杂度大幅增加，而在生成具体代码之前，很难度量这种应用带来的可能提升。

循环展开是一种简单但有用的方法，能够增大可以有效调度的直线代码片段的规模。这种转换在各种处理器上都非常有用，从前面研究过的简单流水线，到多发射超标量，再到本章后面要研究的VLIW。

=== 冒险与竞争

|====
|结构冒险|缺乏硬件支持导致，可以在设计流水线时避免
|数据冒险|一个指令必须等待其他指令的结果才能完成导致的停顿为数据冒险，采用前递或旁路、动态调度技术优化
|控制冒险|在分支判断结果未出现时，无法得知下一条指令是什么，导致停顿。采用分支预测技术优化
|====

TIP: 流水线中有一种情况，在下一个时钟周期中下一条指令无法执行。这种情况被称为冒险（hazard).我们将介绍三种冒险。结构冒险第一种冒险叫作结构冒险(structural hazard)。即硬件不支持多条指令在同一时钟周期执行。在洗衣例子中，如果用洗衣烘干一体机而不是分开的洗衣机和烘干机，或者如果你的室友正在做其他事情而不能收好衣服，都会发生结构冒险。这时，我们精心设计的流水线就会受到破坏。如上所述，RISC-V指令系统是面向流水线设计的，这使得设计人员在设计流水线时很容易避免结构冒险。然而，假设图4-29的流水线结构只有一个而不是两个存储器，那么如果有第四条指令，则会发生第一条指令从存储器取数据的同时第四条指令从同一存储器取指令，流水线会发生结构冒险。数据冒险由于一个步骤必须等待另一个步骤完成而导致的流水线停顿叫作数据冒险(data hazard)。假设你在叠衣服时发现一只袜子找不到与之匹配的另一只。一种可能的策略是跑到房间，在衣橱中找，看是否能找到另一只。显然，当你在找袜子时，完成烘干准备被折叠的衣服和那些已经洗完准备去烘干的衣服，不得不停顿等待。在计算机流水线中，数据冒险源于一条指令依赖于前面一条尚在流水线中的指令(这种关系在洗衣例子中并不存在)。例如，假设有一条加法指令，它后面紧跟着一条使用加法的和的减法指令(x19)：add x19.x0,x1sub x2,×19.×3在不做任何干预的情况下，这一数据冒险会严重地阻碍流水线。add指令直到第五个阶段才写结果，这将浪费三个时钟周期。尽管可以尝试通过编译器来消除这些冒险，但结果并不令人满意。这些依赖经常发生，并且导致的延迟太长，所以不可能指望编译器将我们从这个困境中解救出来一种基本的解决方案是基于以下发现：不需要等待指令完成就可以尝试解决数据冒险。对于上面的代码序列，一旦ALU计算出加法的和，就可将其作为减法的输入。向内部资源添加额外的硬件以尽快找到缺少的运算项的方法，称为前递（forwarding）或旁路(bypassing)


=== 例外

==== RISC-V体系结构中如何处理例外

==== 流水线实现中的例外

=== 指令间的并行性

编译器或处理器来猜测指令的行为并提前开始执行。如果猜测正确则进行指令提交，错误则清除结果并从执行正确的指令。

- 推测的概念

- 基于硬件的推测

- 以多发射和静态调度来利用指令级并行

- 以动态调度、多发射和推测来利用指令级并行

- 用于指令交付和推测的高级技术

== 存储层次结构

=== 存储技术及其优化

- SRAM技术

- DRAM，SDRAM技术

- 闪存、磁盘

- 图形数据RAM

- 堆叠式或嵌入式DRAM

- 相变存储器技术

=== 存储层次结构的一般框架

缓存是位于处理器与存储器之间的速度更快的存储器。作用为将存储器中的数据提前放入速度更快的缓存中，处理器读写数据时先在缓存内查找，从而同时获得大容量与高速的存储器。

|====
|写穿透|处理器在进行写操作时同时向缓存与主存中写入，为避免写主存引起的长延时，还会增加写缓冲区。
|写返回|处理器进行写操作时只对缓存进行写入，并标记脏位。在这个块需要替换时才会写到主存中。此方法减少了对主存的频繁写入。
|====

==== 块的位置

.块的识别方法以及定位方法
[options="header"]
|=======================
|机制|定位方法
|直接映射|索引
|组相联|索引组，查找组中的元素
|全相联|查找所有cache表项
|=======================

==== 块的识别

==== 块的替换

==== 写入策略

==== 失效的定义

==== 汉明编码

==== 3C模型

==== cache的性能评估

==== 优化缓存性能

=== 提高存储器系统的可靠性

=== 使用有限状态自动机控制简单的cache

=== 虚拟存储器和虚拟机

要实现多个程序同时运行，共享内存空间。将内存划分并通过页表将程序与真实的物理地址相联系，这样在程序看来是自己独占内存。

虚拟机可以使多个用户共享同一台计算机，且用户本身感知不到其他用户的存在。虚拟机监视器（VMM）决定如何将虚拟资源映射到物理资源上。

==== 页的存放、查找、失效

==== 快速地址变换技术（TLB）

==== 通过虚拟存储器提供保护

==== 通过虚拟机提供保护

==== 对虚拟机监视器的要求

==== 虚拟机的指令集体系结构支持

==== 虚拟机对虚拟存储器和I/O的影响

==== 扩展指令集


== 数据级并行

单指令流多数据流（SIMD）使得一条向量指令代表了多条指令，同时流水化处理多条数据，从而减少了指令获取和解码的带宽。同时由于每条向量指令的行为已知，可以有效避免竞争冒险的出现。

=== 向量体系结构

==== 向量处理器的工作原理

==== 向量执行时间

==== 单指令流多数据流（SIMD）

==== 向量长度寄存器

处理未知向量长度的循环

条带挖掘技术使得每个向量运算都是针对向量大小小于或等于最大向量长度的情况来完成的。

==== 谓词寄存器（Predicate Registers）

允许处理器在执行指令时跳过某些操作，从而实现分支控制。

==== 存储体

==== 步幅

==== 向量体系中稀疏矩阵的处理

==== 向量体系结构编程

=== 图形处理器

==== GPU编程



NOTE: 写一个整体的简单总结,写不了就留TODO,以后再补.

* NVIDIA GPU拥有强大的并行处理能力和高带宽存储结构，通过大量的核心对大量数据进行并行处理。
* 其本质是一个多线程SIMD处理器，并且拥有更多处理器，每个处理器的通道更多，多线程硬件也更多。
* 适合处理大量相同类型的并行任务。

=== 检测与增强循环级并行

==== 查找相关

==== 清除相关计算



== 线程级并行

在多个处理器上同时执行多个线程，提高程序性能及吞吐量。

处理器之间共享数据有两种方法：1.所有处理器共享一块内存（集中式共享存储器/对称共享存储器）。2.每个处理器有自己的内存但其他处理器可以访问（分布式共享存储器）

=== 多处理器体系结构

=== 集中式/对称共享存储器体系结构

多处理器需要解决缓存一致性问题。

使用监听一致性协议。多核CPU各自保存数据副本，如果一个核心对数据进行了修改，那么其他核心保存的数据将过期。通过写失效来保证数据同步。

==== 多处理器缓存一致性概念

==== 一致性的基本实现方案

==== 监听一致性协议

==== 基本一致性协议的拓展

==== 对称共享存储器多处理器与监听协议的局限性

==== 实现监听缓存一致性

=== 集中式/对称共享存储器多处理器的性能

多个处理器共享同一块内存，处理器之间可以很方便的共享资源，并且处理器之间通信比分布式要快。但是处理器访问内存都要占用总线，当处理器数量较多时会因为带宽不足而影响性能。同时也容易出项竞争冒险现象。如果内存损坏，会影响整个系统的工作，稳定性不如分布式共享存储器结构

==== 商业工作负载对性能的影响

==== 多道程序和操作系统工作负载对性能的影响

=== 分布式共享存储器和目录一致性

集中式/对称共享存储器体系结构由于总线带宽等限制，处理器比较少。分布式共享存储器结构则是每个处理器有独立存储器，以允许增加更多核以及处理器。

同时为了减少带宽占用，使用了目录一致性协议。每个处理器在写数据时，只对目录进行通信。目录记录了数据的所有者以及一致性状态等信息。目录与存储器一起分配，使得不同的一致性请求访问不同的目录，从而防止竞争冒险且减少了带宽占用。

==== 目录式缓存一致性协议

目录式缓存一致性协议能有效减少维持缓存一致性的流量，可以扩展到大量处理器的系统中去。缺陷是在有较多处理器情况下目录储存开销较大，且访问内存时因为需要查目录，可能增加访问延迟。

当一个处理器请求访问一个内存块时，会首先查询目录以获取状态。

|===
|写操作|如果其他处理器内存块内有缓存该内存块，那么目录发出无效化消息通知其他处理器使他们的副本无效。

|读操作|目录更新共享列表。
|===

==== 实例目录协议

=== 同步基础

原语不可分割，要么全部执行成功，要么全部执行失败，可以利用它来实现同步机制以及减少竞争冒险现象的发生。

实现自旋锁：

函数不断使用原子操作获取锁，如果已经被占用则一直在循环中自旋等待解锁。

适用于希望短时间获取这个锁以及在锁可用时锁定延迟较低的情形。但是自旋锁会占用CPU资源，不适用于长时间等待以及可能出现死锁的情况。

==== 基本硬件原语

==== 使用一致性实现锁

=== 存储器一致性模型

存储器一致性模型保证了在多处理器对内存的访问的数据一致性，不同模型决定了处理器如何对待内存访问的顺序性，从而影响程序的正确性和性能。

==== 简介

|===
| |顺序一致性|要求所有处理器的而操作按照程序中规定的顺序执行，且所有处理器看到的操作顺序一致
.4+|宽松一致性模型|完全存储排序或处理器一致性|仅放松W->R顺序。保持了写操作之间的顺序
|部分存储排序|放松W->R和W->W顺序
|弱排序 |放松所有四种顺序
|释放一致性|放松所有四种顺序。区分了用于获取对共享变量访问的同步操作（标记为S~A~）和那些释放对象以允许其他处理器获取访问的同步操作（标记为S
~R~）
|===

==== 宽松一致性模型

=== 多处理器测试基准和性能模型

- 性能模型

- Roofline模型

==== 两代Opteron的比较


== 集群、仓库级计算机（WSC）

高性能计算（HPC）集群与仓库级计算机（WSC）应用领域不同。前者更倾向于线程级并行，主要解决复杂问题。而后者强调请求级并行，同时为多个用户进行服务。

=== 仓库级计算机的编程模型与工作负载

=== 仓库级计算机的计算机体系结构

==== 存储

==== WSC存储器层次结构

=== 仓库级计算机的效率与成本

==== 测量WSC的效率

==== WSC的成本

=== 云计算：效用计算的回报


== 领域专用体系结构

针对特定领域定制处理器，加速某些应用程序以实现更好的性能与性价比

=== DSA指导原则

=== 示例领域：深度神经网络

NOTE: 写成列表,算法和网络类型分开.写不出来可以不写,留个简单的列表就行

* 算法

- DNN的神经元
- 训练与推理
- 多层感知机
- 批数据
- 量化

* 网络类型
- 卷积神经网络
- 循环神经网络

=== Google的张量处理单元——一种数据中心推理加速器

* TPU的起源

* TPU体系结构

* TPU指令集体系结构

* TPU微体系结构

* TPU实现

* TPU软件

* 改进TPU

=== Microsoft Catapult——一种灵活的数据中心加速器

* Catapult实现与体系结构

* Catapult软件

* Catapult上的CNN

* Catapult上的搜索加速

* Catapult Ver 1 的部署

* Catapult Ver 2

=== Intel Crest——一种用于训练的数据中心加速器

=== Pixel Visual Core——一种个人移动设备图像处理单元

* ISP——IPU的硬连线前身

* Pixel Visual Core 软件

* Pixel Visual Core 体系结构的理念

* Pixel Visual Core 光晕

* Pixel Visual Core 的处理器

* Pixel Visual Core 指令集体系结构

* Pixel Visual Core 示例

* Pixel Visual Core PE

* 二维行缓冲区及其控制器

* Pixel Visual Core 实现
